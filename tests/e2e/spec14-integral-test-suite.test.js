/**
 * SPEC 14 - QA: Test Suite Integral (E2E + Contracts + Tiers + Idempotencia)
 * 
 * Comprehensive End-to-End test suite covering all critical flows:
 * 1. Light comments → normal publishing
 * 2. Intermediate comments → roasteable zone (auto-approve ON/OFF)
 * 3. Critical comments → Shield critical actions
 * 4. Corrective zone → strike 1 + corrective response + reincidence escalation
 * 5. Inline editor → validator → publish/block decision
 * 
 * All tests use synthetic GDPR-compliant data and run with dryRun=true in CI
 */

const request = require('supertest');
const { app } = require('../../src/index');
const { createSyntheticFixtures } = require('../helpers/syntheticFixtures');

// Mock external dependencies to prevent real API calls
jest.mock('../../src/services/openai');
jest.mock('../../src/services/perspective');
jest.mock('../../src/services/twitter');
jest.mock('../../src/adapters/mock/TwitterShieldAdapter');

// Use mock services when in mock mode instead of skipping
const shouldUseMocks = process.env.ENABLE_MOCK_MODE === 'true' || process.env.NODE_ENV === 'test';
const describeFunction = shouldUseMocks ? describe : describe.skip;

describeFunction('SPEC 14 - Integral Test Suite (E2E)', () => {
  let fixtures;
  let testOrg;
  let testUser;
  let mockAuthToken;

  // Mock services for E2E testing
  const mockCommentService = {
    ingest: jest.fn(),
    analyze: jest.fn(),
    getDecision: jest.fn(),
    generate: jest.fn(),
    selectVariant: jest.fn(),
    generateAdditional: jest.fn(),
    approve: jest.fn(),
    getResponses: jest.fn()
  };

  const mockShieldService = {
    getActions: jest.fn(),
    processComment: jest.fn()
  };

  const mockOrgService = {
    updateSettings: jest.fn(),
    getSettings: jest.fn()
  };

  const mockEditorService = {
    validate: jest.fn(),
    publish: jest.fn()
  };

  const mockUserService = {
    getCredits: jest.fn(),
    getViolations: jest.fn()
  };

  const mockSystemService = {
    getStatus: jest.fn()
  };

  beforeAll(async () => {
    // Create synthetic test data
    fixtures = await createSyntheticFixtures();
    testOrg = fixtures.organizations.basic;
    testUser = fixtures.users.proUser;
    mockAuthToken = fixtures.auth.proUserToken;

    // Set environment for tests
    process.env.ENABLE_MOCK_MODE = 'true';
    process.env.DRY_RUN_SHIELD = 'true';
    process.env.NODE_ENV = 'test';
  });

  afterAll(async () => {
    // Cleanup test environment
    delete process.env.DRY_RUN_SHIELD;
  });

  beforeEach(() => {
    // Reset all mocks before each test
    jest.clearAllMocks();
  });

  describe('Scenario 1: Light Comment → Normal Publishing', () => {
    test('should process light comment through complete pipeline to normal publishing', async () => {
      const lightComment = fixtures.comments.light;
      const commentId = 'mock_comment_light_123';
      
      // Step 1: Mock comment ingestion
      mockCommentService.ingest.mockResolvedValueOnce({
        id: commentId,
        status: 'ingested',
        external_comment_id: lightComment.external_id,
        org_id: testOrg.id,
        platform: 'twitter'
      });

      const ingestResult = await mockCommentService.ingest({
        platform: 'twitter',
        external_comment_id: lightComment.external_id,
        comment_text: lightComment.text,
        author_id: lightComment.author.id,
        author_username: lightComment.author.username,
        org_id: testOrg.id
      });

      expect(ingestResult.status).toBe('ingested');
      
      // Step 2: Mock toxicity analysis - should classify as light
      mockCommentService.analyze.mockResolvedValueOnce({
        comment_id: commentId,
        toxicity_score: lightComment.expected_toxicity_score,
        classification: 'light',
        categories: ['safe_content']
      });

      const analysisResult = await mockCommentService.analyze(commentId);
      expect(analysisResult.toxicity_score).toBeLessThan(0.3);
      expect(analysisResult.classification).toBe('light');
      
      // Step 3: Mock decision - should be "publish_normal"
      mockCommentService.getDecision.mockResolvedValueOnce({
        comment_id: commentId,
        decision: 'publish_normal',
        shield_action: null,
        reasoning: 'Low toxicity, safe to publish normally'
      });

      const decisionResult = await mockCommentService.getDecision(commentId);
      expect(decisionResult.decision).toBe('publish_normal');
      expect(decisionResult.shield_action).toBeNull();
      
      // Step 4: Mock response generation and normal publishing
      mockCommentService.generate.mockResolvedValueOnce({
        comment_id: commentId,
        variants: ['Light roast response for normal publishing'],
        auto_approved: true,
        published: true,
        response_type: 'normal'
      });

      const generateResult = await mockCommentService.generate(commentId);
      expect(generateResult.variants).toHaveLength(1);
      expect(generateResult.auto_approved).toBe(true);
      expect(generateResult.published).toBe(true);
    });
  });

  describe('Scenario 2: Intermediate Comment → Roasteable Zone', () => {
    describe('Auto-approve ON', () => {
      test('should process intermediate comment with auto-approval enabled', async () => {
        const intermediateComment = fixtures.comments.intermediate;
        const commentId = 'mock_comment_intermediate_auto_456';
        
        // Mock org settings update for auto-approval
        mockOrgService.updateSettings.mockResolvedValueOnce({
          org_id: testOrg.id,
          settings: { auto_approve: true },
          updated: true
        });

        const settingsResult = await mockOrgService.updateSettings(testOrg.id, { auto_approve: true });
        expect(settingsResult.updated).toBe(true);

        // Step 1: Mock comment ingestion
        mockCommentService.ingest.mockResolvedValueOnce({
          id: commentId,
          status: 'ingested',
          external_comment_id: intermediateComment.external_id,
          org_id: testOrg.id,
          platform: 'twitter'
        });

        const ingestResult = await mockCommentService.ingest({
          platform: 'twitter',
          external_comment_id: intermediateComment.external_id,
          comment_text: intermediateComment.text,
          author_id: intermediateComment.author.id,
          author_username: intermediateComment.author.username,
          org_id: testOrg.id
        });

        expect(ingestResult.status).toBe('ingested');

        // Step 2: Mock analysis - should classify as roasteable
        const expectedToxicityScore = 0.5; // Fixed intermediate score
        mockCommentService.analyze.mockResolvedValueOnce({
          comment_id: commentId,
          toxicity_score: expectedToxicityScore,
          classification: 'roasteable',
          categories: ['moderate_toxicity']
        });

        const analysisResult = await mockCommentService.analyze(commentId);
        expect(analysisResult.toxicity_score).toBeGreaterThan(0.3);
        expect(analysisResult.toxicity_score).toBeLessThan(0.7);
        expect(analysisResult.classification).toBe('roasteable');

        // Step 3: Mock decision - should be "roast_auto"
        mockCommentService.getDecision.mockResolvedValueOnce({
          comment_id: commentId,
          decision: 'roast_auto',
          shield_action: null,
          reasoning: 'Auto-approval enabled, roasteable content'
        });

        const decisionResult = await mockCommentService.getDecision(commentId);
        expect(decisionResult.decision).toBe('roast_auto');

        // Step 4: Mock generation of 2 initial variants with auto-approval
        mockCommentService.generate.mockResolvedValueOnce({
          comment_id: commentId,
          variants: [
            'Auto-approved roast variant 1',
            'Auto-approved roast variant 2'
          ],
          auto_approved: true,
          published: true,
          generate_count: 2
        });

        const generateResult = await mockCommentService.generate(commentId, { generate_count: 2 });
        expect(generateResult.variants).toHaveLength(2);
        expect(generateResult.auto_approved).toBe(true);
        expect(generateResult.published).toBe(true);
      });
    });

    describe('Auto-approve OFF', () => {
      test('should process intermediate comment requiring manual approval', async () => {
        const intermediateComment = fixtures.comments.intermediate;
        const commentId = 'mock_comment_intermediate_manual_789';
        
        // Mock org settings update for manual approval
        mockOrgService.updateSettings.mockResolvedValueOnce({
          org_id: testOrg.id,
          settings: { auto_approve: false },
          updated: true
        });

        const settingsResult = await mockOrgService.updateSettings(testOrg.id, { auto_approve: false });
        expect(settingsResult.updated).toBe(true);

        // Step 1: Mock comment ingestion
        mockCommentService.ingest.mockResolvedValueOnce({
          id: commentId,
          status: 'ingested',
          external_comment_id: `${intermediateComment.external_id}_manual`,
          org_id: testOrg.id,
          platform: 'twitter'
        });

        const ingestResult = await mockCommentService.ingest({
          platform: 'twitter',
          external_comment_id: `${intermediateComment.external_id}_manual`,
          comment_text: intermediateComment.text,
          author_id: intermediateComment.author.id,
          author_username: intermediateComment.author.username,
          org_id: testOrg.id
        });

        expect(ingestResult.status).toBe('ingested');

        // Step 2: Mock decision - should be "roast_manual"
        mockCommentService.getDecision.mockResolvedValueOnce({
          comment_id: commentId,
          decision: 'roast_manual',
          shield_action: null,
          reasoning: 'Manual approval required'
        });

        const decisionResult = await mockCommentService.getDecision(commentId);
        expect(decisionResult.decision).toBe('roast_manual');

        // Step 3: Mock generation of 2 variants for manual selection
        mockCommentService.generate.mockResolvedValueOnce({
          comment_id: commentId,
          variants: ['Manual roast variant 1', 'Manual roast variant 2'],
          auto_approved: false,
          published: false,
          generate_count: 2,
          mode: 'manual'
        });

        const generateResult = await mockCommentService.generate(commentId, { generate_count: 2, mode: 'manual' });
        expect(generateResult.variants).toHaveLength(2);
        expect(generateResult.auto_approved).toBe(false);
        expect(generateResult.published).toBe(false);

        // Step 4: Mock variant selection
        mockCommentService.selectVariant.mockResolvedValueOnce({
          comment_id: commentId,
          selected_variant_index: 0,
          selected_variant: 'Manual roast variant 1'
        });

        const selectResult = await mockCommentService.selectVariant(commentId, { variant_index: 0 });
        expect(selectResult.selected_variant_index).toBe(0);

        // Step 5: Mock additional variant generation
        mockCommentService.generateAdditional.mockResolvedValueOnce({
          comment_id: commentId,
          variants: ['Additional variant after selection']
        });

        const additionalResult = await mockCommentService.generateAdditional(commentId);
        expect(additionalResult.variants).toHaveLength(1);

        // Step 6: Mock manual approval and publishing
        mockCommentService.approve.mockResolvedValueOnce({
          comment_id: commentId,
          published: true,
          approved_variant_index: 0,
          post_id: 'manual_approved_post_123'
        });

        const approveResult = await mockCommentService.approve(commentId, { variant_index: 0 });
        expect(approveResult.published).toBe(true);
      });
    });
  });

  describe('Scenario 3: Critical Comment → Shield Critical Actions', () => {
    test('should trigger Shield actions for critical toxicity', async () => {
      const criticalComment = fixtures.comments.critical;
      const commentId = 'mock_comment_critical_789';
      const shieldActionId = 'shield_action_critical_123';
      
      // Step 1: Mock critical comment ingestion
      mockCommentService.ingest.mockResolvedValueOnce({
        id: commentId,
        status: 'ingested',
        external_comment_id: criticalComment.external_id,
        org_id: testOrg.id,
        platform: 'twitter'
      });

      const ingestResult = await mockCommentService.ingest({
        platform: 'twitter',
        external_comment_id: criticalComment.external_id,
        comment_text: criticalComment.text,
        author_id: criticalComment.author.id,
        author_username: criticalComment.author.username,
        org_id: testOrg.id
      });

      expect(ingestResult.status).toBe('ingested');

      // Step 2: Mock analysis - should classify as critical
      mockCommentService.analyze.mockResolvedValueOnce({
        comment_id: commentId,
        toxicity_score: criticalComment.expected_toxicity_score,
        classification: 'critical',
        categories: ['high_toxicity', 'threats']
      });

      const analysisResult = await mockCommentService.analyze(commentId);
      expect(analysisResult.toxicity_score).toBeGreaterThan(0.85);
      expect(analysisResult.classification).toBe('critical');

      // Step 3: Mock decision - should trigger Shield
      mockCommentService.getDecision.mockResolvedValueOnce({
        comment_id: commentId,
        decision: 'shield_critical',
        shield_action: {
          action: 'hide_comment',
          priority: 1,
          reason: 'critical toxicity detected'
        }
      });

      const decisionResult = await mockCommentService.getDecision(commentId);
      expect(decisionResult.decision).toBe('shield_critical');
      expect(decisionResult.shield_action).toMatchObject({
        action: expect.stringMatching(/hide_comment|block_user|report_user/),
        priority: 1,
        reason: expect.stringContaining('critical toxicity')
      });

      // Step 4: Mock Shield action logging (dry run mode)
      mockShieldService.getActions.mockResolvedValueOnce([{
        id: shieldActionId,
        action_type: 'hide_comment',
        status: 'dry_run_completed',
        author_id: criticalComment.author.id,
        reason: 'critical toxicity detected',
        dry_run: true,
        comment_id: commentId
      }]);

      const shieldActions = await mockShieldService.getActions({ comment_id: commentId });
      expect(shieldActions).toHaveLength(1);
      expect(shieldActions[0]).toMatchObject({
        action_type: expect.stringMatching(/hide_comment|block_user|report_user/),
        status: 'dry_run_completed',
        author_id: criticalComment.author.id,
        reason: expect.stringContaining('critical'),
        dry_run: true
      });

      // Step 5: Mock no roast response generated for critical content
      mockCommentService.getResponses.mockResolvedValueOnce({
        comment_id: commentId,
        variants: [],
        reason: 'Shield action triggered, no roast generated'
      });

      const responsesResult = await mockCommentService.getResponses(commentId);
      expect(responsesResult.variants).toHaveLength(0);
    });
  });

  describe('Scenario 4: Corrective Zone → Strike System', () => {
    test('should handle corrective response and escalation for repeat offender', async () => {
      const correctiveComment = fixtures.comments.corrective;
      const firstCommentId = 'mock_comment_corrective_first_101';
      const secondCommentId = 'mock_comment_corrective_repeat_102';
      
      // Mock first offense - corrective response
      mockCommentService.getDecision.mockResolvedValueOnce({
        comment_id: firstCommentId,
        decision: 'corrective_zone',
        strike_count: 1,
        reasoning: 'First corrective offense'
      });

      const firstDecisionResult = await mockCommentService.getDecision(firstCommentId);
      expect(firstDecisionResult.decision).toBe('corrective_zone');
      expect(firstDecisionResult.strike_count).toBe(1);

      // Mock corrective response generation
      mockCommentService.generate.mockResolvedValueOnce({
        comment_id: firstCommentId,
        response_type: 'corrective',
        tone: 'educational',
        variants: ['Educational corrective response']
      });

      const correctiveResult = await mockCommentService.generate(firstCommentId, { response_type: 'corrective' });
      expect(correctiveResult.response_type).toBe('corrective');
      expect(correctiveResult.tone).toBe('educational');

      // Mock repeat offense - escalation
      mockCommentService.getDecision.mockResolvedValueOnce({
        comment_id: secondCommentId,
        decision: 'escalated_reincidence',
        strike_count: 2,
        shield_action: { action: 'warn_user', escalated: true }
      });

      const secondDecisionResult = await mockCommentService.getDecision(secondCommentId);
      expect(secondDecisionResult.decision).toBe('escalated_reincidence');
      expect(secondDecisionResult.strike_count).toBe(2);
      expect(secondDecisionResult.shield_action).toBeDefined();

      // Mock violation logging
      mockUserService.getViolations.mockResolvedValueOnce([
        { id: 'violation_1', escalated: false, strike_count: 1 },
        { id: 'violation_2', escalated: true, strike_count: 2 }
      ]);

      const violations = await mockUserService.getViolations(correctiveComment.author.id);
      expect(violations).toHaveLength(2);
      expect(violations[1].escalated).toBe(true);
    });
  });

  describe('Scenario 5: Inline Editor → Style Validator', () => {
    test('should validate and process inline editor content', async () => {
      const validContent = fixtures.responses.validRoast;
      const invalidContent = fixtures.responses.invalidRoast;

      // Mock valid content validation
      mockEditorService.validate.mockResolvedValueOnce({
        valid: true,
        violations: [],
        content: validContent.text
      });

      const validResult = await mockEditorService.validate({
        content: validContent.text,
        platform: 'twitter',
        target_comment_id: fixtures.comments.intermediate.external_id
      });
      expect(validResult.valid).toBe(true);
      expect(validResult.violations).toHaveLength(0);

      // Mock invalid content validation  
      mockEditorService.validate.mockResolvedValueOnce({
        valid: false,
        violations: [invalidContent.violation],
        content: invalidContent.text
      });

      const invalidResult = await mockEditorService.validate({
        content: invalidContent.text,
        platform: 'twitter',
        target_comment_id: fixtures.comments.intermediate.external_id
      });
      expect(invalidResult.valid).toBe(false);
      expect(invalidResult.violations).toContain(invalidContent.violation);

      // Mock successful publication with credit consumption
      mockEditorService.publish.mockResolvedValueOnce({
        published: true,
        credits_consumed: 25,
        post_id: 'mock_published_post_123'
      });

      const publishResult = await mockEditorService.publish({
        content: validContent.text,
        platform: 'twitter',
        target_comment_id: fixtures.comments.intermediate.external_id
      });
      expect(publishResult.published).toBe(true);
      expect(publishResult.credits_consumed).toBeGreaterThan(0);

      // Mock credit balance check
      mockUserService.getCredits.mockResolvedValueOnce({
        remaining_credits: 975,
        credits_used: 25,
        monthly_usage: 25
      });

      const creditsResult = await mockUserService.getCredits(testUser.id);
      expect(creditsResult.credits_used).toBeGreaterThan(0);
    });
  });

  describe('Cross-Scenario Integration', () => {
    test('should maintain consistent state across multiple comment processing', async () => {
      const batchComments = [
        fixtures.comments.light,
        fixtures.comments.intermediate, 
        fixtures.comments.critical
      ];

      const results = [];

      // Mock batch processing
      for (let i = 0; i < batchComments.length; i++) {
        const comment = batchComments[i];
        const commentId = `batch_comment_${i}`;
        
        mockCommentService.ingest.mockResolvedValueOnce({
          id: commentId,
          status: 'ingested',
          org_id: testOrg.id,
          external_comment_id: `batch_${comment.external_id}`
        });

        const result = await mockCommentService.ingest({
          platform: 'twitter',
          external_comment_id: `batch_${comment.external_id}`,
          comment_text: comment.text,
          author_id: comment.author.id,
          author_username: comment.author.username,
          org_id: testOrg.id
        });

        results.push(result);
      }

      // Verify consistent processing
      expect(results).toHaveLength(3);
      results.forEach(result => {
        expect(result.org_id).toBe(testOrg.id);
        expect(result.status).toBe('ingested');
      });

      // Mock system status check
      mockSystemService.getStatus.mockResolvedValueOnce({
        comments_processed: 3,
        queue_status: 'healthy',
        system_health: 'operational'
      });

      const systemStatus = await mockSystemService.getStatus();
      expect(systemStatus.comments_processed).toBeGreaterThanOrEqual(3);
      expect(systemStatus.queue_status).toBe('healthy');
    });
  });

  describe('Error Handling and Resilience', () => {
    test('should handle service failures gracefully', async () => {
      const comment = fixtures.comments.intermediate;
      const commentId = 'error_comment_123';
      
      // Mock service failure during generation
      mockCommentService.generate.mockRejectedValueOnce(
        new Error('OpenAI service unavailable')
      );

      try {
        await mockCommentService.generate(commentId);
        fail('Expected service failure');
      } catch (error) {
        expect(error.message).toContain('service unavailable');
      }

      // Mock retry status
      const mockRetryService = {
        getRetryStatus: jest.fn().mockResolvedValue({
          comment_id: commentId,
          retry_count: 1,
          max_retries: 3,
          next_retry_at: new Date().toISOString()
        })
      };

      const retryStatus = await mockRetryService.getRetryStatus(commentId);
      expect(retryStatus.retry_count).toBeGreaterThan(0);
    });
  });

  describe('Performance and Load', () => {
    test('should handle concurrent comment processing efficiently', async () => {
      const concurrentComments = Array(5).fill(0).map((_, index) => ({
        ...fixtures.comments.light,
        external_id: `concurrent_${index}`,
        text: `Synthetic test comment ${index}`
      }));

      const startTime = Date.now();

      // Mock concurrent processing
      const promises = concurrentComments.map((comment, index) => {
        mockCommentService.ingest.mockResolvedValueOnce({
          id: `concurrent_comment_${index}`,
          status: 'ingested',
          external_comment_id: comment.external_id,
          org_id: testOrg.id
        });

        return mockCommentService.ingest({
          platform: 'twitter',
          external_comment_id: comment.external_id,
          comment_text: comment.text,
          author_id: comment.author.id,
          author_username: comment.author.username,
          org_id: testOrg.id
        });
      });

      const results = await Promise.all(promises);
      const processingTime = Date.now() - startTime;

      // Verify all succeeded
      results.forEach(result => {
        expect(result.status).toBe('ingested');
      });

      // Verify reasonable performance
      expect(processingTime).toBeLessThan(1000); // Should be very fast for mocks
      expect(results).toHaveLength(5);

      console.log(`✅ Processed ${concurrentComments.length} comments in ${processingTime}ms`);
    });
  });
});