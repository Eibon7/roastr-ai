# Roastr.ai

Roastr.ai es un MVP (Producto M√≠nimo Viable) que genera "roasts" o respuestas sarc√°sticas e ingeniosas a comentarios usando inteligencia artificial. El proyecto est√° desplegado en Vercel como una funci√≥n serverless usando Express y OpenAI GPT-4o mini.

## Introducci√≥n

Roastr.ai es una herramienta que analiza comentarios y genera respuestas humor√≠sticas y sarc√°sticas de forma autom√°tica. Es ideal para moderaci√≥n de contenido con un toque de humor, permitiendo responder a comentarios t√≥xicos o inapropiados con ingenio en lugar de censura directa.

**Caracter√≠sticas principales:**
- Generaci√≥n de roasts usando OpenAI GPT-4o mini
- Detecci√≥n autom√°tica de idioma (espa√±ol/ingl√©s)
- API REST desplegada en Vercel
- Frontend web minimalista
- CLI para uso local

## Arquitectura

El proyecto usa una arquitectura simple basada en Node.js + Express:

- **Backend**: `src/index.js` - Servidor Express con endpoints de API
- **Frontend**: `public/index.html` - Interfaz web b√°sica con HTML/CSS/JS vanilla
- **Despliegue**: Vercel serverless functions usando `vercel.json`
- **CLI**: `src/cli.js` - Herramienta de l√≠nea de comandos para testing local

La aplicaci√≥n se ejecuta como una funci√≥n serverless en Vercel, lo que permite escalabilidad autom√°tica y costos reducidos.

## Endpoints

### `GET /`
Sirve el frontend web desde `public/index.html`.

### `POST /roast`
Genera un roast usando la API de OpenAI.

**Par√°metros:**
```json
{
  "message": "Tu comentario aqu√≠"
}
```

**Respuesta:**
```json
{
  "roast": "Tu roast generado por IA"
}
```

### `POST /csv-roast`
Genera un roast simulado usando un sistema de plantillas (actualmente mock, futura integraci√≥n con CSV).

**Par√°metros:**
```json
{
  "message": "Tu comentario aqu√≠"
}
```

**Respuesta:**
```json
{
  "roast": "üéØ Roast desde CSV simulado para: \"Tu comentario aqu√≠\""
}
```

## Variables de entorno

Crea un archivo `.env` en la ra√≠z del proyecto con las siguientes variables:

```env
OPENAI_API_KEY=tu_clave_openai_aqui
ROASTR_API_KEY=tu_api_key_roastr_aqui
DEBUG=true # Opcional, activa logs detallados

# Variables para integraci√≥n con Twitter/X
TWITTER_BEARER_TOKEN=tu_bearer_token_aqui
TWITTER_APP_KEY=tu_app_key_aqui
TWITTER_APP_SECRET=tu_app_secret_aqui
TWITTER_ACCESS_TOKEN=tu_access_token_aqui
TWITTER_ACCESS_SECRET=tu_access_secret_aqui
ROAST_API_URL=https://tu-url-vercel.vercel.app # Opcional, URL de la API
```

### Descripci√≥n de variables:

**API de Roast:**
- `OPENAI_API_KEY`: Clave de API de OpenAI para generar los roasts
- `ROASTR_API_KEY`: Clave de autenticaci√≥n personalizada para el endpoint /roast
- `DEBUG`: Activa logs detallados en consola (opcional)

**Integraci√≥n con Twitter/X:**
- `TWITTER_BEARER_TOKEN`: Token Bearer de Twitter para leer menciones (OAuth 2.0)
- `TWITTER_APP_KEY`: Consumer Key de la aplicaci√≥n de Twitter
- `TWITTER_APP_SECRET`: Consumer Secret de la aplicaci√≥n de Twitter
- `TWITTER_ACCESS_TOKEN`: Access Token para publicar tweets
- `TWITTER_ACCESS_SECRET`: Access Token Secret para publicar tweets
- `ROAST_API_URL`: URL base de la API de roast (opcional, por defecto usa producci√≥n)

## Configuraci√≥n de Vercel

El archivo `vercel.json` configura el despliegue en Vercel:

```json
{
  "version": 2,
  "builds": [
    { "src": "src/index.js", "use": "@vercel/node" }
  ],
  "routes": [
    { "src": "/(.*)", "dest": "src/index.js" }
  ]
}
```

**Puntos importantes:**
- Todas las rutas se redirigen a `src/index.js`
- Para que funcionen `/roast` y `/csv-roast`, el `vercel.json` debe apuntar a `"dest": "src/index.js"`
- Las variables de entorno deben configurarse tambi√©n en el Vercel Dashboard

## Despliegue

### Pasos para desplegar:

```bash
# Instalar dependencias
npm install

# Autenticarse en Vercel
vercel login

# Vincular proyecto
vercel link

# Desplegar a producci√≥n
vercel --prod
```

**Notas importantes:**
- Despu√©s del despliegue, Vercel genera una URL nueva
- Siempre prueba en la URL m√°s reciente generada por `vercel --prod`
- Configura las variables de entorno en el Vercel Dashboard despu√©s del primer despliegue

## Uso de la API

### Endpoint POST /roast

```bash
curl -X POST "https://TU_URL_VERCEL.vercel.app/roast" \
  -H "Content-Type: application/json" \
  -H "x-api-key: TU_ROASTR_API_KEY" \
  -d '{"message": "Your code is terrible"}'
```

### Endpoint POST /csv-roast

```bash
curl -X POST "https://TU_URL_VERCEL.vercel.app/csv-roast" \
  -H "Content-Type: application/json" \
  -d '{"message": "Your code is terrible"}'
```

### Ejemplo de respuesta exitosa:

```json
{
  "roast": "Vaya, qu√© original. Seguro que tardaste horas en pensar esa obra maestra."
}
```

### Ejemplo de respuesta de error:

```json
{
  "error": "Debes enviar un campo \"message\" v√°lido."
}
```

## Modo Debug

Activa el modo debug estableciendo `DEBUG=true` en tu archivo `.env`:

```env
DEBUG=true
```

**Beneficios del modo debug:**
- Logs detallados en la consola
- Informaci√≥n de par√°metros de entrada
- Claves de API truncadas para seguridad
- Detalles de errores de la API de OpenAI

## CSV Roast (Pendiente)

**Estado actual:** El endpoint `/csv-roast` devuelve un mock simulado.

**Funcionalidad futura:** 
- Leer√° roasts predefinidos desde un archivo CSV
- Permitir√° respuestas m√°s r√°pidas sin usar tokens de OpenAI
- Sistema de plantillas personalizable

## CLI Local

Para testing local, usa el CLI:

```bash
# Roast simple
npm run roast "Tu comentario aqu√≠"

# Ejemplo
npm run roast "Este c√≥digo es horrible"
```

El CLI se conecta autom√°ticamente a la URL de producci√≥n configurada.

## Bot de Twitter/X

**Funcionalidad:** El bot monitorea menciones a tu cuenta en Twitter/X y responde autom√°ticamente con roasts generados por IA usando el plan Essential (gratuito) de Twitter API.

‚ö†Ô∏è **IMPORTANTE:** El bot est√° optimizado para funcionar con el plan Essential de Twitter API, que **NO** soporta streaming en tiempo real. Usa polling por lotes para detectar menciones.

### Configuraci√≥n de Twitter/X:

1. **Crear aplicaci√≥n en Twitter Developer Portal:**
   - Ve a [developer.twitter.com](https://developer.twitter.com)
   - Crea un nuevo proyecto y aplicaci√≥n
   - Obt√©n las credenciales necesarias

2. **Configurar permisos:**
   - La aplicaci√≥n necesita permisos de "Read and Write"
   - Activa "OAuth 1.0a" para publicar tweets
   - Obt√©n Bearer Token para "OAuth 2.0" (leer menciones)

3. **A√±adir credenciales al .env:**
   ```env
   TWITTER_BEARER_TOKEN=tu_bearer_token
   TWITTER_APP_KEY=tu_consumer_key
   TWITTER_APP_SECRET=tu_consumer_secret
   TWITTER_ACCESS_TOKEN=tu_access_token
   TWITTER_ACCESS_SECRET=tu_access_token_secret
   ```

### Ejecutar el bot:

```bash
# Modo batch (una sola ejecuci√≥n, recomendado para testing)
npm run twitter:batch

# Modo por defecto (polling continuo cada 5 minutos)
npm run twitter

# Nota: streaming mode est√° desactivado para compatibilidad con Essential API
```

### Caracter√≠sticas del bot:

- **Modo batch:** Una sola ejecuci√≥n para procesar menciones recientes (ideal para cron jobs)
- **Modo polling:** Ejecuci√≥n continua con intervalos configurables (por defecto: 5 minutos)
- **Compatible con Essential API:** Optimizado para el plan gratuito de Twitter API
- **Detecci√≥n de toxicidad:** Actualmente usa un stub que siempre permite roasts (preparado para Perspective API)
- **Prevenci√≥n de duplicados:** Rastrea menciones procesadas en `data/processed_mentions.json`
- **Prevenci√≥n de auto-respuestas:** No responde a sus propios tweets
- **Rate limiting configurable:** Controla tweets por hora y delays entre tweets
- **Manejo de errores robusto:** Exponential backoff y reintentos autom√°ticos
- **Logging avanzado:** Logs estructurados con timestamps y contexto detallado

### Configuraci√≥n avanzada del bot:

A√±ade estas variables a tu archivo `.env` para personalizar el comportamiento:

```env
# Bot configuration (opcional)
RUN_MODE=loop                   # Modo de ejecuci√≥n: 'loop' (continuo) o 'single' (una vez)
MAX_TWEETS_PER_HOUR=10          # M√°ximo tweets por hora (default: 10)
MIN_DELAY_BETWEEN_TWEETS=5000   # Delay m√≠nimo entre tweets en ms (default: 5000)
MAX_DELAY_BETWEEN_TWEETS=30000  # Delay m√°ximo entre tweets en ms (default: 30000)
BATCH_INTERVAL_MINUTES=5        # Intervalo de polling en minutos (default: 5, solo para loop)
DEBUG=true                      # Activa logs detallados (default: false)
```

### Modos de ejecuci√≥n:

**üîÑ Loop Mode (por defecto):**
```bash
npm run twitter:batch           # Ejecuta continuamente
RUN_MODE=loop npm run twitter   # Expl√≠citamente en modo loop
```

**‚ö° Single Mode (ideal para cron jobs):**
```bash
RUN_MODE=single npm run twitter:batch    # Una sola ejecuci√≥n y termina
```

### Ejemplos de cron jobs:

```bash
# Cada 5 minutos
*/5 * * * * cd /path/to/roastr-ai && RUN_MODE=single npm run twitter:batch

# Cada 15 minutos con debug
*/15 * * * * cd /path/to/roastr-ai && RUN_MODE=single DEBUG=true npm run twitter:batch

# Cada hora
0 * * * * cd /path/to/roastr-ai && RUN_MODE=single npm run twitter:batch
```

### Logs del bot:

**Logs normales:**
- ‚úÖ Operaciones exitosas
- ‚ö†Ô∏è Advertencias y rate limits
- ‚ùå Errores y fallos
- ‚ÑπÔ∏è Informaci√≥n general

**Logs de debug (DEBUG=true):**
- `[TWITTER-DEBUG]` - Informaci√≥n t√©cnica detallada
- `[BATCH]` - Eventos espec√≠ficos del modo batch
- `[POLLING]` - Eventos del ciclo de polling continuo
- JSON estructurado con contexto completo
- Timestamps ISO precisos
- Datos de performance y m√©tricas

### Archivos generados:

- `data/processed_mentions.json`: Lista de menciones ya procesadas (evita duplicados)
- `data/processed_tweets.json`: Lista de tweets ya procesados (sistema legacy)

## Desarrollo Local

```bash
# Instalar dependencias
npm install

# Modo desarrollo con auto-reload
npm run dev

# Iniciar servidor API
npm run start:api

# Usar CLI local
npm run roast "mensaje de prueba"

# Ejecutar bot de Twitter
npm run twitter:batch   # Una sola ejecuci√≥n (recomendado para testing)
npm run twitter         # Modo polling continuo (recomendado para producci√≥n)
```

## ‚è±Ô∏è Automatizaci√≥n con Cron Jobs

Para ejecutar el bot autom√°ticamente cada X minutos usando cron jobs de macOS:

### üöÄ Configuraci√≥n R√°pida

1. **Verificar script disponible:**
   ```bash
   npm run twitter:batch:single  # Debe ejecutar en modo single y terminar
   ```

2. **Dar permisos al script de cron:**
   ```bash
   chmod +x cron_twitter.sh
   ```

3. **Configurar crontab:**
   ```bash
   crontab -e
   ```
   
   **üí° Tip:** Puedes copiar desde `crontab.example` una de estas l√≠neas seg√∫n el intervalo deseado:
   ```bash
   # Cada 5 minutos
   */5 * * * * /Users/emiliopostigo/roastr-ai/cron_twitter.sh
   
   # Cada 10 minutos
   */10 * * * * /Users/emiliopostigo/roastr-ai/cron_twitter.sh
   
   # Cada 15 minutos
   */15 * * * * /Users/emiliopostigo/roastr-ai/cron_twitter.sh
   
   # Cada 30 minutos
   */30 * * * * /Users/emiliopostigo/roastr-ai/cron_twitter.sh
   
   # Cada hora
   0 * * * * /Users/emiliopostigo/roastr-ai/cron_twitter.sh
   ```

### üìä Monitoreo y Logs

**Ver logs en tiempo real:**
```bash
tail -f /Users/emiliopostigo/roastr-ai/logs/cron_twitter.log
```

**Ver √∫ltimos logs:**
```bash
tail -n 50 /Users/emiliopostigo/roastr-ai/logs/cron_twitter.log
```

**Limpiar logs antiguos:**
```bash
> /Users/emiliopostigo/roastr-ai/logs/cron_twitter.log
```

### üîß Gesti√≥n del Cron Job

**Ver cron jobs activos:**
```bash
crontab -l
```

**Pausar el bot (comentar l√≠nea en crontab):**
```bash
crontab -e
# A√±adir # al inicio de la l√≠nea para desactivarla
# */5 * * * * /Users/emiliopostigo/roastr-ai/cron_twitter.sh
```

**Desactivar completamente:**
```bash
crontab -r  # ‚ö†Ô∏è Esto elimina TODOS los cron jobs
```

### üõ†Ô∏è Troubleshooting

**El cron job no funciona:**
1. Verificar permisos: `ls -la cron_twitter.sh` (debe mostrar `-rwxr-xr-x`)
2. Probar manualmente: `./cron_twitter.sh`
3. Verificar ruta de npm: `which npm` (debe ser `/usr/local/bin/npm`)
4. Revisar logs del sistema: `tail -f /var/log/cron`

**Logs vac√≠os o sin actualizar:**
1. Verificar que el script tiene permisos de escritura en `logs/`
2. Ejecutar manualmente: `npm run twitter:batch:single`
3. Revisar variables de entorno en el servidor

**Rate limiting de Twitter:**
1. Aumentar intervalo en crontab (ej: de */5 a */15 minutos)
2. Verificar l√≠mites en el dashboard de Twitter Developer
3. Ajustar `MAX_TWEETS_PER_HOUR` en `.env`

### üì± Ejemplos de Intervalos Recomendados

| Intervalo | L√≠nea Crontab | Uso Recomendado |
|-----------|---------------|-----------------|
| 5 minutos | `*/5 * * * *` | Respuesta r√°pida, para cuentas activas |
| 15 minutos | `*/15 * * * *` | Balance entre respuesta y l√≠mites API |
| 30 minutos | `*/30 * * * *` | Conservador, ideal para empezar |
| 1 hora | `0 * * * *` | Muy conservador, cuentas con pocas menciones |

**üí° Recomendaci√≥n:** Empezar con 15 minutos y ajustar seg√∫n la actividad de menciones y l√≠mites de API.

## Resumen T√©cnico para IA

```json
{
  "name": "Roastr.ai",
  "stack": ["Node.js", "Express", "Vercel", "Twitter API"],
  "endpoints": ["/", "/roast", "/csv-roast"],
  "env_vars": ["OPENAI_API_KEY", "ROASTR_API_KEY", "DEBUG", "TWITTER_BEARER_TOKEN", "TWITTER_APP_KEY", "TWITTER_APP_SECRET", "TWITTER_ACCESS_TOKEN", "TWITTER_ACCESS_SECRET"],
  "deployment": "vercel --prod",
  "frontend": "public/index.html",
  "backend": "src/index.js",
  "twitter_bot": "src/services/twitter.js",
  "commands": {
    "api": "npm start",
    "cli": "npm run roast",
    "twitter_stream": "npm run twitter:stream",
    "twitter_batch": "npm run twitter:batch",
    "twitter": "npm run twitter"
  }
}
```