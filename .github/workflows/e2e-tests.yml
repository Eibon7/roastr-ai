name: E2E Tests - Manual Approval UI

on:
  pull_request:
    branches: [main, develop]
    paths:
      - 'public/**'
      - 'src/routes/approval.js'
      - 'src/services/roastGeneratorEnhanced.js'
      - 'tests/e2e/**'
      - '.github/workflows/e2e-tests.yml'
  push:
    branches: [main]
    paths:
      - 'public/**'
      - 'src/routes/approval.js'
      - 'tests/e2e/**'

jobs:
  e2e-tests:
    runs-on: ubuntu-latest
    timeout-minutes: 15

    services:
      postgres:
        image: postgres:14
        env:
          POSTGRES_DB: roastr_test
          POSTGRES_USER: postgres
          POSTGRES_PASSWORD: postgres
        options: >-
          --health-cmd "pg_isready -U postgres"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432

    steps:
      - name: Checkout code
        uses: actions/checkout@v5

      - name: Setup Node.js
        uses: actions/setup-node@v6
        with:
          node-version: '20'
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Install Playwright browsers
        run: npx playwright install --with-deps chromium

      - name: Setup environment variables
        run: |
          echo "NODE_ENV=test" >> $GITHUB_ENV
          echo "DATABASE_URL=postgresql://postgres:postgres@localhost:5432/roastr_test" >> $GITHUB_ENV
          echo "SUPABASE_URL=${{ secrets.SUPABASE_URL }}" >> $GITHUB_ENV
          echo "SUPABASE_SERVICE_KEY=${{ secrets.SUPABASE_SERVICE_KEY }}" >> $GITHUB_ENV
          echo "OPENAI_API_KEY=${{ secrets.OPENAI_API_KEY }}" >> $GITHUB_ENV

      - name: Setup test database
        run: |
          # Apply consolidated schema (includes all migrations)
          PGPASSWORD=postgres psql -h localhost -U postgres -d roastr_test -f database/schema.sql
        env:
          DATABASE_URL: postgresql://postgres:postgres@localhost:5432/roastr_test

      - name: Start application server
        run: |
          # Start server and capture logs for debugging
          npm run start > server.log 2>&1 &
          SERVER_PID=$!
          echo "Started server pid=$SERVER_PID"
          
          # Wait for health endpoint with retries (60s total)
          echo "Waiting for server to be ready (up to 60s)..."
          for i in {1..30}; do
            if curl -sSf http://localhost:3000/health --max-time 2 >/dev/null 2>&1; then
              echo "✅ Server ready"
              break
            fi
            sleep 2
          done
          
          # Verify server is actually ready
          if ! curl -sSf http://localhost:3000/health --max-time 2 >/dev/null 2>&1; then
            echo "❌ Server failed to start, printing server.log:"
            cat server.log || true
            echo "=== Process status ==="
            ps aux | grep node || true
            kill $SERVER_PID || true
            exit 1
          fi
        env:
          NODE_ENV: test
          DATABASE_URL: postgresql://postgres:postgres@localhost:5432/roastr_test
          # Use safe test defaults instead of empty strings
          SUPABASE_URL: "http://localhost:54321/mock"
          SUPABASE_SERVICE_KEY: "test-service-key"
          SUPABASE_ANON_KEY: "test-anon-key"
          OPENAI_API_KEY: "test-openai-key"
          PORT: 3000
          ENABLE_MOCK_MODE: "true"

      - name: Run E2E tests
        run: npm run test:e2e
        env:
          NODE_ENV: test
          BASE_URL: http://localhost:3000

      - name: Upload test results on failure
        if: failure()
        uses: actions/upload-artifact@v5
        with:
          name: playwright-report
          path: playwright-report/
          retention-days: 7

      - name: Upload screenshots on failure
        if: failure()
        uses: actions/upload-artifact@v5
        with:
          name: test-screenshots
          path: docs/test-evidence/issue-419/
          retention-days: 7

      - name: Generate test summary
        if: always()
        run: |
          echo "## E2E Test Results" >> $GITHUB_STEP_SUMMARY
          if [ -f playwright-report/results.json ]; then
            # Extract test stats with defensive parsing
            node -e "
              const fs = require('fs');
              try {
                const results = JSON.parse(fs.readFileSync('playwright-report/results.json', 'utf8'));
                let totalTests = 0;
                let passed = 0;
                let failed = 0;
                let skipped = 0;

                if (Array.isArray(results.suites)) {
                  results.suites.forEach(suite => {
                    if (suite && Array.isArray(suite.specs)) {
                      suite.specs.forEach(spec => {
                        if (spec && Array.isArray(spec.tests)) {
                          totalTests += spec.tests.length;
                          spec.tests.forEach(test => {
                            if (test && Array.isArray(test.results)) {
                              const lastResult = test.results[test.results.length - 1];
                              if (lastResult) {
                                if (lastResult.status === 'passed') passed++;
                                else if (lastResult.status === 'failed') failed++;
                                else if (lastResult.status === 'skipped') skipped++;
                              }
                            }
                          });
                        }
                      });
                    }
                  });
                }

                const duration = results.duration || 0;
                const durationSeconds = (duration / 1000).toFixed(2);
                const emoji = failed > 0 ? '❌' : '✅';

                console.log(\`\${emoji} **\${totalTests} tests** completed in \${durationSeconds}s\`);
                console.log(\`- ✅ Passed: \${passed}\`);
                if (failed > 0) console.log(\`- ❌ Failed: \${failed}\`);
                if (skipped > 0) console.log(\`- ⏭️ Skipped: \${skipped}\`);
              } catch (error) {
                console.log('⚠️ Error parsing test results:', error.message);
              }
            " >> $GITHUB_STEP_SUMMARY || echo "⚠️ Test results available in artifacts" >> $GITHUB_STEP_SUMMARY
          else
            echo "⚠️ Test results will be available after tests complete" >> $GITHUB_STEP_SUMMARY
          fi

      - name: Comment PR with test results
        if: github.event_name == 'pull_request' && github.actor != 'dependabot[bot]' && always()
        continue-on-error: true
        uses: actions/github-script@v8
        with:
          script: |
            const fs = require('fs');
            let comment = '## E2E Test Results\\n\\n';

            try {
              const resultsPath = 'playwright-report/results.json';
              if (fs.existsSync(resultsPath)) {
                const results = JSON.parse(fs.readFileSync(resultsPath, 'utf8'));

                // Defensive validation of results structure
                if (!results || typeof results !== 'object') {
                  throw new Error('Invalid results structure');
                }

                // Handle different possible structures from Playwright JSON reporter
                let totalTests = 0;
                let passed = 0;
                let failed = 0;
                let skipped = 0;

                if (Array.isArray(results.suites)) {
                  // Count tests from suites
                  results.suites.forEach(suite => {
                    if (suite && Array.isArray(suite.specs)) {
                      totalTests += suite.specs.length;
                      suite.specs.forEach(spec => {
                        if (spec && Array.isArray(spec.tests)) {
                          spec.tests.forEach(test => {
                            if (test && Array.isArray(test.results)) {
                              const lastResult = test.results[test.results.length - 1];
                              if (lastResult) {
                                if (lastResult.status === 'passed') passed++;
                                else if (lastResult.status === 'failed') failed++;
                                else if (lastResult.status === 'skipped') skipped++;
                              }
                            }
                          });
                        }
                      });
                    }
                  });
                } else {
                  // Fallback: try to get stats from top-level properties
                  totalTests = results.stats?.expected || 0;
                  passed = results.stats?.passed || 0;
                  failed = results.stats?.failed || 0;
                  skipped = results.stats?.skipped || 0;
                }

                const duration = results.duration || 0;
                const durationSeconds = (duration / 1000).toFixed(2);

                if (totalTests > 0) {
                  const emoji = failed > 0 ? '❌' : '✅';
                  comment += `${emoji} **${totalTests} tests** completed in ${durationSeconds}s\\n\\n`;
                  comment += `- ✅ Passed: ${passed}\\n`;
                  if (failed > 0) comment += `- ❌ Failed: ${failed}\\n`;
                  if (skipped > 0) comment += `- ⏭️ Skipped: ${skipped}\\n`;
                  comment += `\\nFull report available in workflow artifacts.`;
                } else {
                  comment += '⚠️ No test results found in report.';
                }
              } else {
                comment += '⚠️ Test results file not found.';
              }
            } catch (error) {
              comment += `Error generating summary: ${error.message}\\n\\n`;
              comment += `Please check the workflow logs for details.`;
            }

            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: comment
            });
