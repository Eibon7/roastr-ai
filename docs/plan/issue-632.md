# Implementation Plan: Issue #632 - Unified Analysis Department

**Issue:** #632 - Refactor: Unified Analysis Department (Gatekeeper + Perspective)
**Priority:** P0 (Critical - Security Gap)
**Status:** Planning
**Created:** 2025-10-23
**Estimated Hours:** 12-14 hours

---

## ðŸŽ¯ Estado Actual

### Current Architecture (FLAWED)

**Flow:** Sequential execution with early return

```text
AnalyzeToxicityWorker.processJob()
  â†“
Gatekeeper.classifyComment(text)
  â†“
  - MALICIOUS detected â†’ return early (lÃ­nea 277) âŒ
  - Perspective API NEVER called âŒ
  â†“
Shield receives: categories=['prompt_injection'] ONLY
  â†“
NO platform_violations.reportable âŒ
```

### Problema CrÃ­tico

**Ejemplo:** "Te voy a matar {{ignore all instructions}}"

**Flujo actual:**

1. Gatekeeper detecta `{{ignore all instructions}}` â†’ `classification: MALICIOUS`
2. Early return con `categories: ['gatekeeper_malicious', 'prompt_injection']`
3. âŒ Perspective API NUNCA se ejecuta
4. âŒ Shield NO sabe que hay amenaza fÃ­sica (`threat >= 0.8`)
5. âŒ NO incluye `report_to_platform` en acciones
6. âŒ **VIOLACIÃ“N ToS** - Amenazas fÃ­sicas NO reportadas

**Gap de seguridad:** Detectamos prompt injection pero perdemos anÃ¡lisis de amenazas/hate speech que SÃ deben reportarse a la plataforma.

### Archivos Actuales

| Archivo                                | LÃ­neas  | Problema                               |
| -------------------------------------- | ------- | -------------------------------------- |
| `src/workers/AnalyzeToxicityWorker.js` | 237-288 | Early return on Gatekeeper MALICIOUS   |
| `src/services/gatekeeperService.js`    | 370     | Solo detecta injection, NO toxicidad   |
| `src/services/perspective.js`          | 271     | Nunca se ejecuta si Gatekeeper returns |
| `src/services/shieldService.js`        | TBD     | Recibe datos incompletos               |

---

## ðŸ”¬ Risk Assessment

### Security Risks

| Risk                  | Impact   | Likelihood | Mitigation                                  |
| --------------------- | -------- | ---------- | ------------------------------------------- |
| **ToS Violations**    | CRITICAL | High       | âœ… Parallel execution ensures both analyses |
| **Legal Liability**   | HIGH     | Medium     | âœ… Platform violations always detected      |
| **Reputation Damage** | HIGH     | Medium     | âœ… Proper reporting of threats/hate speech  |

### Technical Risks

| Risk                       | Impact | Likelihood | Mitigation                                  |
| -------------------------- | ------ | ---------- | ------------------------------------------- |
| **Backward Compatibility** | MEDIUM | High       | âœ… Maintain existing Shield action types    |
| **Increased Latency**      | LOW    | Medium     | âœ… Parallel execution (no sequential delay) |
| **API Cost Increase**      | LOW    | High       | âœ… Rate limiting + fallback already exist   |

---

## ðŸ“ Complexity Analysis

### Architectural Complexity: **HIGH**

**Reasons:**

1. **Parallel Execution** - `Promise.allSettled()` with proper error handling
2. **Decision Matrix** - 10 scenarios (see issue table)
3. **Action Tags** - New schema for explicit actions
4. **Backward Compatibility** - Existing Shield integrations must work

### Implementation Phases

**Phase 1: Core Services** (4-5 hours)

- âœ… `AnalysisDepartmentService.js` - Orchestrator
- âœ… `AnalysisDecisionEngine.js` - Decision logic

**Phase 2: Worker Refactor** (2-3 hours)

- âœ… Simplify `AnalyzeToxicityWorker.js`
- âœ… Remove decision logic, delegate to department

**Phase 3: Shield Integration** (2-3 hours)

- âœ… Modify `ShieldService.executeActions()` to consume `action_tags[]`
- âœ… Maintain backward compatibility

**Phase 4: Tests** (3-4 hours)

- âœ… Integration tests for decision matrix (9+ scenarios)
- âœ… Edge case tests (fallback, failures)
- âœ… Shield integration tests

---

## ðŸ—ï¸ Implementation Approach

### 1. Create AnalysisDepartmentService

**File:** `src/services/AnalysisDepartmentService.js`

**Responsibilities:**

- Orchestrate Gatekeeper + Perspective in **parallel** using `Promise.allSettled()`
- Handle fallback if one service fails
- Pass results to Decision Engine
- Return unified output schema

**Key Methods:**

```javascript
class AnalysisDepartmentService {
  async analyzeComment(commentText, userContext) {
    // 1. Parallel execution
    const [gatekeeperResult, perspectiveResult] = await Promise.allSettled([
      this.gatekeeper.classifyComment(commentText),
      this.perspective.analyzeToxicity(commentText)
    ]);

    // 2. Delegate to decision engine
    const decision = await this.decisionEngine.determineDirection(
      gatekeeperResult,
      perspectiveResult,
      userContext
    );

    return decision; // Unified output schema
  }
}
```

**Testing:**

- Unit tests: Parallel execution, fallback scenarios
- Integration tests: Full flow with real services (mocked APIs)

---

### 2. Create AnalysisDecisionEngine

**File:** `src/services/AnalysisDecisionEngine.js`

**Responsibilities:**

- Implement decision matrix (10 scenarios from issue)
- Detect platform violations (`threat >= 0.8`, `identity_attack >= 0.8`)
- Calculate combined scores
- Generate action tags (`hide_comment`, `report_to_platform`, etc.)

**Key Methods:**

```javascript
class AnalysisDecisionEngine {
  determineDirection(gatekeeperResult, perspectiveResult, userContext) {
    // 1. Check for platform violations
    const violations = this.detectPlatformViolations(perspectiveResult);

    // 2. Apply decision matrix
    if (gatekeeperResult.classification === 'MALICIOUS') {
      if (violations.has_violations) {
        // BOTH injection + threat â†’ SHIELD with report
        return {
          direction: 'SHIELD',
          action_tags: ['hide_comment', 'block_user', 'report_to_platform'],
          ...
        };
      } else {
        // ONLY injection â†’ SHIELD without report
        return {
          direction: 'SHIELD',
          action_tags: ['hide_comment', 'block_user', 'check_reincidence'],
          ...
        };
      }
    }

    // 3. Continue matrix logic...
  }

  detectPlatformViolations(perspectiveResult) {
    const { threat, identity_attack, severe_toxicity } = perspectiveResult.scores;

    const violations = [];
    if (threat >= 0.8) violations.push('physical_threat');
    if (identity_attack >= 0.8) violations.push('identity_attack');
    if (severe_toxicity >= 0.95) violations.push('harassment');

    return {
      has_violations: violations.length > 0,
      violation_types: violations,
      reportable: violations.length > 0
    };
  }
}
```

**Testing:**

- Unit tests: Decision matrix (10 scenarios)
- Edge cases: Ambiguous scores, missing data

---

### 3. Refactor AnalyzeToxicityWorker

**File:** `src/workers/AnalyzeToxicityWorker.js`

**Changes:**

- **REMOVE** lines 237-288 (Gatekeeper early return logic)
- **ADD** call to `analysisDepartment.analyzeComment()`
- **SIMPLIFY** routing based on `decision.direction`

**Before (FLAWED):**

```javascript
// Lines 237-288
const gatekeeperResult = await this.gatekeeperService.classifyComment(commentText);

if (gatekeeperResult.classification === 'MALICIOUS') {
  // Early return - Perspective NEVER runs âŒ
  return { ... };
}

// Perspective runs only if Gatekeeper allows
const perspectiveResult = await this.perspectiveAPI.analyzeToxicity(commentText);
```

**After (FIXED):**

```javascript
// Call unified Analysis Department
const analysisResult = await this.analysisDepartment.analyzeComment(commentText, userContext);

// Route based on direction
switch (analysisResult.direction) {
  case 'SHIELD':
    await this.handleShieldAction(comment, analysisResult);
    break;
  case 'ROAST':
    await this.handleRoastAction(comment, analysisResult);
    break;
  case 'PUBLISH':
    await this.handlePublishAction(comment, analysisResult);
    break;
}
```

**Testing:**

- Integration tests: Verify routing for all directions
- Backward compatibility: Existing Shield tests still pass

---

### 4. Modify ShieldService

**File:** `src/services/shieldService.js`

**Changes:**

- Modify `executeActions()` to accept `action_tags[]` parameter
- Map action tags to platform-specific actions
- Maintain backward compatibility with existing callers

**Before:**

```javascript
executeActions(decision) {
  // Infers actions from severity/categories
  const actions = this.inferActions(decision.severity, decision.categories);
  ...
}
```

**After:**

```javascript
executeActions(decision) {
  // Use explicit action_tags if provided, fallback to inference
  const actions = decision.action_tags || this.inferActions(decision.severity, decision.categories);

  // Execute actions
  actions.forEach(async (actionTag) => {
    if (actionTag === 'report_to_platform') {
      await this.reportToP latform(comment, decision.metadata.platform_violations);
    }
    // ... other actions
  });
}
```

**Testing:**

- Unit tests: Action tag mapping
- Integration tests: Platform-specific actions

---

### 5. Database Schema Changes (Optional)

**Table:** `comments` (or `shield_events`)

**New Fields:**

```sql
ALTER TABLE comments ADD COLUMN direction VARCHAR(20); -- PUBLISH, ROAST, SHIELD
ALTER TABLE comments ADD COLUMN action_tags TEXT[]; -- Array of action tags
ALTER TABLE comments ADD COLUMN analysis_metadata JSONB; -- Full metadata

-- Example:
{
  "direction": "SHIELD",
  "action_tags": ["hide_comment", "block_user", "report_to_platform"],
  "analysis_metadata": {
    "security": { "classification": "MALICIOUS", "injection_score": 0.95 },
    "toxicity": { "toxicity_score": 0.88, "threat_score": 0.92 },
    "platform_violations": { "has_violations": true, "reportable": true }
  }
}
```

**Migration:** Create migration script if schema changes needed

---

## ðŸ§ª Test Strategy

### Decision Matrix Tests (9 scenarios)

| Test | Condition                        | Expected Direction | Expected Action Tags                                              |
| ---- | -------------------------------- | ------------------ | ----------------------------------------------------------------- |
| 1    | Injection ONLY                   | SHIELD             | `hide_comment`, `block_user`, `check_reincidence` (NO report)     |
| 2    | Threat ONLY                      | SHIELD             | `hide_comment`, `block_user`, **`report_to_platform`**            |
| 3    | Injection + Threat               | SHIELD             | `hide_comment`, `block_user`, **`report_to_platform`**            |
| 4    | Toxicity â‰¥ Ï„_critical            | SHIELD             | `hide_comment`, `block_user`, `check_reincidence`                 |
| 5    | Ï„_shield â‰¤ score < Ï„_critical    | SHIELD             | `hide_comment`, (+`report` if reincident)                         |
| 6    | Zona correctiva                  | ROAST              | `roast_correctivo`, `add_strike_1`, `check_reincidence`           |
| 7    | Ï„_roast_lower â‰¤ score < Ï„_shield | ROAST              | `roast_{soft\|balanced\|hard}`, `auto_approve`/`require_approval` |
| 8    | POSITIVE classification          | PUBLISH            | `publish_normal`                                                  |
| 9    | score < Ï„_roast_lower            | PUBLISH            | `publish_normal`                                                  |

### Edge Case Tests (6 scenarios)

| Test | Scenario             | Expected Behavior                           |
| ---- | -------------------- | ------------------------------------------- |
| 1    | Both services fail   | SHIELD (fail-safe), `require_manual_review` |
| 2    | Gatekeeper fails     | Use Perspective + pattern matching          |
| 3    | Perspective fails    | Use OpenAI Moderation fallback              |
| 4    | Ambiguous scores     | Use Decision Engine tie-breaker logic       |
| 5    | Missing user context | Use default thresholds                      |
| 6    | API timeout          | Retry with exponential backoff              |

### Test Files

**Integration Tests:**

- `tests/integration/analysis-department.test.js` (NEW) - 15+ tests
- `tests/integration/analysis-decision-engine.test.js` (NEW) - 10+ tests

**Unit Tests:**

- `tests/unit/services/AnalysisDepartmentService.test.js` (NEW)
- `tests/unit/services/AnalysisDecisionEngine.test.js` (NEW)
- `tests/unit/workers/AnalyzeToxicityWorker.test.js` (MODIFIED) - Verify refactor

**Coverage Target:** â‰¥90% for all new services

---

## ðŸ“ Documentation Updates

### GDD Nodes

**1. `docs/nodes/shield.md`**

- Add "Analysis Department Integration" section
- Update architecture diagram with parallel execution
- Document `action_tags[]` schema
- Add "Platform Violations Detection" section

**2. `docs/nodes/roast.md`**

- Update "Toxicity Analysis" section with unified flow
- Document new routing logic

### Additional Documentation

**3. `docs/architecture/analysis-department.md`** (NEW)

- Full architecture explanation
- Decision matrix reference
- Action tags specification
- Platform violations mapping

---

## ðŸŽ¯ Acceptance Criteria Mapping

**From Issue #632:**

- [ ] AC1: `AnalysisDepartmentService` ejecuta Gatekeeper + Perspective en paralelo
- [ ] AC2: `AnalysisDecisionEngine` implementa matriz de decisiÃ³n completa
- [ ] AC3: Comentario **SOLO injection** â†’ `direction: SHIELD`, **NO** `report_to_platform`
- [ ] AC4: Comentario **SOLO amenaza** â†’ `direction: SHIELD`, **SÃ** `report_to_platform`
- [ ] AC5: Comentario **ambos** â†’ `direction: SHIELD`, **SÃ** `report_to_platform`
- [ ] AC6: Fallback Gatekeeper fails â†’ usa Perspective + pattern matching
- [ ] AC7: Fallback Perspective fails â†’ usa OpenAI Moderation
- [ ] AC8: Fallback crÃ­tico ambos fallen â†’ rechaza por seguridad
- [ ] AC9: `AnalyzeToxicityWorker` simplificado (solo orquesta, no decide)
- [ ] AC10: `ShieldService` consume `action_tags` directamente
- [ ] AC11: Tests cubren matriz completa (9 escenarios)
- [ ] AC12: DocumentaciÃ³n actualizada en `docs/nodes/shield.md` y `docs/nodes/roast.md`

---

## ðŸš€ Implementation Order

### Sprint 1: Core Services (4-5 hours)

1. Create `src/services/AnalysisDepartmentService.js`
   - Parallel execution with `Promise.allSettled()`
   - Fallback handling
   - Integration with existing services

2. Create `src/services/AnalysisDecisionEngine.js`
   - Decision matrix implementation
   - Platform violations detection
   - Action tags generation

3. Unit tests for both services

### Sprint 2: Worker Refactor (2-3 hours)

4. Refactor `src/workers/AnalyzeToxicityWorker.js`
   - Remove lines 237-288 (early return logic)
   - Add call to Analysis Department
   - Simplify routing

5. Update `src/services/shieldService.js`
   - Accept `action_tags[]` parameter
   - Maintain backward compatibility

6. Integration tests for refactored worker

### Sprint 3: Shield Integration (2-3 hours)

7. Modify Shield action execution
   - Map `action_tags` to platform actions
   - Implement `report_to_platform` action

8. Platform-specific action tests

### Sprint 4: Testing & Documentation (3-4 hours)

9. Create `tests/integration/analysis-department.test.js`
   - 9 decision matrix tests
   - 6 edge case tests

10. Update GDD documentation
    - `docs/nodes/shield.md`
    - `docs/nodes/roast.md`
    - Create `docs/architecture/analysis-department.md`

11. Run full test suite (100% passing target)

---

## ðŸŽ“ CodeRabbit Lessons Applied

### Pre-Implementation Checklist

âœ… Read `docs/patterns/coderabbit-lessons.md`
âœ… Tests written BEFORE implementation (TDD)
âœ… Use `const` by default, `let` only if mutable
âœ… Use `logger.js` instead of `console.log`
âœ… Add JSDoc to exported functions
âœ… NO hardcoded credentials
âœ… Implement retry logic for API calls
âœ… Update GDD nodes with "Agentes Relevantes"

### Specific Patterns

**Error Handling (#5):**

- âœ… Use specific error codes (`E_GATEKEEPER_FAIL`, `E_PERSPECTIVE_FAIL`)
- âœ… Implement retry with exponential backoff
- âœ… Log with context (attempt number, user ID)

**Testing (#2):**

- âœ… TDD: Write tests FIRST
- âœ… Cover happy + error + edge cases
- âœ… Verify mock calls: `expect(mock).toHaveBeenCalledWith(...)`

**Security (#6):**

- âœ… NO env vars in docs
- âœ… NO sensitive data in logs
- âœ… Validate all inputs

---

## âš ï¸ Risks & Mitigations

### Risk 1: Increased API Calls

**Issue:** Perspective API now called for ALL comments (not just non-malicious)

**Mitigation:**

- Existing rate limiting already in place (`perspective.js:227`)
- Fallback to OpenAI Moderation if quota exceeded
- Cost acceptable for security gain

### Risk 2: Latency Increase

**Issue:** Parallel execution may add ~100-200ms

**Mitigation:**

- Parallel execution means no sequential delay
- Both services already have timeouts (10s)
- User won't notice <200ms difference

### Risk 3: Backward Compatibility

**Issue:** Existing Shield integrations expect specific data format

**Mitigation:**

- Maintain `severity` and `categories` fields
- `action_tags` is ADDITIVE (optional parameter)
- Fallback to inference if `action_tags` not provided

---

## ðŸŽ¯ Definition of Done

- [ ] All 12 AC passing
- [ ] Test coverage â‰¥90% for new services
- [ ] Full test suite passing (0 failures)
- [ ] GDD nodes updated (shield.md, roast.md)
- [ ] CodeRabbit review: 0 comments
- [ ] CI/CD passing (all checks green)
- [ ] Agent receipts generated (Orchestrator, Test Engineer, Guardian)

---

## ðŸ“Š Estimated Effort

| Phase              | Estimated Hours | Confidence |
| ------------------ | --------------- | ---------- |
| Core Services      | 4-5 hours       | 90%        |
| Worker Refactor    | 2-3 hours       | 85%        |
| Shield Integration | 2-3 hours       | 80%        |
| Testing & Docs     | 3-4 hours       | 85%        |
| **TOTAL**          | **12-14 hours** | **85%**    |

---

**Recommendation:** âœ… **CREATE**

**Justification:**

- P0 security gap requires immediate fix
- Architecture is sound (parallel execution, fail-safe)
- Backward compatibility maintained
- Test strategy comprehensive
- Implementation path clear

**Blockers:** None identified

**Dependencies:** None (refactor internal)

---

**Created by:** Orchestrator Agent
**Date:** 2025-10-23
**Next Steps:** Proceed with Sprint 1 (Core Services implementation)

---

## ðŸ”’ Post-Merge Security Enhancement (CodeRabbit Review #634)

**Date:** 2025-10-23
**PR:** #634 - Unified Analysis Department
**Review:** https://github.com/Eibon7/roastr-ai/pull/634#issuecomment-3437346199
**Severity:** P1 Critical (Security)

### Issue Identified

**CodeRabbit Finding:** Gatekeeper fallback returns `classification: 'NEUTRAL'` and `is_prompt_injection: false`, allowing low-toxicity prompt injections to bypass security during Gatekeeper outages.

**Attack Vector:**

1. Transient Gatekeeper outage occurs
2. User submits comment with prompt injection + low toxicity
3. Gatekeeper fails â†’ fallback returns NEUTRAL
4. Perspective succeeds with low toxicity score (e.g., 0.30)
5. Decision matrix routes to ROAST (bypassing security)

### Security Gap Closed

**Root Cause:** Fallback logic assumed safety (NEUTRAL) when security service unavailable. Downstream decision logic ignored the `fallback` flag.

**Fix Applied:**

1. **Conservative Fallback Classification** (`AnalysisDecisionEngine.js:103-121`):
   - Changed from `classification: 'NEUTRAL'` to `'MALICIOUS'`
   - Set `is_prompt_injection: true` (conservative assumption)
   - Added `fallback_reason` for audit trail

2. **Explicit Fallback Detection** (`AnalysisDecisionEngine.js:265-284`):
   - Added RULE 0 to decision matrix (highest priority)
   - Explicit check for `fallback && fallback_reason`
   - Forces SHIELD with action_tags: `['gatekeeper_unavailable', 'require_manual_review']`

### Test Coverage

**New Tests Added** (`tests/integration/analysis-department.test.js`):

- **Edge 2 (updated):** Gatekeeper fails, Perspective detects clean comment â†’ SHIELD (conservative)
- **Edge 7 (new):** Gatekeeper fails + injection-like text â†’ SHIELD
- **Edge 8 (new):** Gatekeeper fails + high toxicity + platform violations â†’ SHIELD

**Test Results:** 20/20 passing (18 original + 2 new)

### Documentation Updates

**GDD Nodes Updated:**

1. **`docs/nodes/shield.md`** - Added "Fallback Security Policy" section
   - Conservative fallback strategy documented
   - Action tags specification (`gatekeeper_unavailable`)
   - Monitoring recommendations

2. **`docs/nodes/roast.md`** - Added "Fallback Mode" in decision matrix
   - RULE 0 documentation (fallback â†’ SHIELD)
   - Security principle: fail-safe over convenience

### Impact Assessment

**Security Improvement:**

- âœ… Closes security gap identified by CodeRabbit
- âœ… Fail-safe principle consistently applied
- âœ… All fallback scenarios now route to SHIELD (manual review required)

**User Impact:**

- âš ï¸ False positives increase during Gatekeeper outages (intentional)
- âœ… Manual review ensures no malicious content published
- âœ… Monitoring alerts detect service degradation

**Performance Impact:**

- âœ… No latency increase (decision logic adjustment only)
- âœ… No additional API calls

### Monitoring & Alerting

**Action Tags for Monitoring:**

- `gatekeeper_unavailable` - Track fallback frequency
- `require_manual_review` - Queue depth monitoring

**Recommended Alerts:**

- Alert if `gatekeeper_unavailable` appears in >5% of comments (service issue)
- Alert if manual review queue depth exceeds threshold
- Dashboard for Gatekeeper service SLA and uptime

### Architectural Principle

**Fail-Safe Design:** When security services unavailable, default to blocking rather than allowing. Security over convenience.

**Trade-off Accepted:** Increased false positives during outages (clean comments blocked) is preferable to false negatives (malicious content published).

---

**Fix Status:** âœ… Complete
**Tests:** 20/20 passing
**Documentation:** Updated
**Review:** CodeRabbit issue resolved
