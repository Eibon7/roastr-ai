# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

## Project Overview

This is a comprehensive multi-tenant toxicity detection and roast generation system for social media platforms. The project features a scalable architecture built with Node.js, supporting multiple organizations with dedicated workers, cost control, and automated moderation through the Shield system.

## Business Model

The platform operates on a subscription-based model with multiple tiers:

- **Free Plan**: Basic roast generation with limited features and platform access
- **Starter Plan**: ‚Ç¨5/month - Enhanced features with increased limits and additional platforms
- **Pro Plan**: ‚Ç¨15/month - Advanced features, custom styles, multiple platforms, analytics
- **Plus Plan**: ‚Ç¨50/month - Premium tier with maximum capabilities, priority support, custom integrations

*Note: Enterprise plans are not currently available but may be considered for future releases.*

## Development Commands

```bash
# Start the application
npm start

# Start in development mode with auto-reload
npm run dev

# Start API server
npm run start:api

# Use CLI tool
npm run roast "your message here"

# Run Twitter bot
npm run twitter

# Install dependencies
npm install

# Setup admin and test users for backoffice development (Issue #237)
npm run setup:test-users:dry      # Preview what will be created
npm run setup:test-users          # Execute the setup

# Multi-tenant worker system
npm run workers:start           # Start all workers
npm run workers:status          # Check worker status
npm run workers:status:watch    # Monitor workers in real-time

# Queue management
npm run queue:status            # Check queue status
npm run queue:manage            # Interactive queue management
npm run queue:monitor           # Real-time queue monitoring
npm run queue:clear-all         # Clear all queues
npm run queue:retry             # Retry failed jobs

# Testing
npm test                        # Run all tests
npm run test:coverage           # Run tests with coverage

# GDD Runtime Validation (Graph-Driven Development 2.0)
node scripts/validate-gdd-runtime.js --full    # Validate entire system
node scripts/validate-gdd-runtime.js --diff    # Validate only changed nodes
node scripts/validate-gdd-runtime.js --node=shield  # Validate specific node
node scripts/validate-gdd-runtime.js --report  # Generate report only
node scripts/validate-gdd-runtime.js --ci      # CI mode (exit 1 on errors)
node scripts/validate-gdd-runtime.js --drift   # Include drift prediction
node scripts/watch-gdd.js                      # Watch mode (development)

# GDD Drift Prediction (Phase 8)
node scripts/predict-gdd-drift.js --full       # Predict drift risk for all nodes
node scripts/predict-gdd-drift.js --node=shield  # Analyze specific node
node scripts/predict-gdd-drift.js --ci         # CI mode (exit 1 if high-risk)
node scripts/predict-gdd-drift.js --create-issues  # Create GitHub issues for high-risk nodes

# GDD Auto-Repair (Phase 10)
node scripts/auto-repair-gdd.js --dry-run      # Show what would be fixed
node scripts/auto-repair-gdd.js --auto-fix     # Apply fixes automatically
node scripts/auto-repair-gdd.js --ci           # CI mode (exit 1 on errors)

# GDD Health Scoring (Phase 7)
node scripts/score-gdd-health.js --ci          # Score all nodes
node scripts/compute-gdd-health.js --threshold=95  # Check health threshold

# GDD Agent Interface (Phase 14)
node scripts/agents/agent-interface.js --simulate  # Test agent permissions
node scripts/agents/secure-write.js --test     # Test secure write protocol
node scripts/agents/telemetry-bus.js --listen  # Listen to telemetry events
node scripts/agents/telemetry-bus.js --test    # Test telemetry bus

# GDD Watch with Agents (Phase 14.1)
node scripts/watch-gdd.js --agents-active      # Watch with autonomous agents
node scripts/watch-gdd.js --telemetry          # Watch with telemetry display
node scripts/watch-gdd.js --agents-active --telemetry  # Full agent integration
```

## Multi-Tenant Project Structure

```
src/
‚îú‚îÄ‚îÄ index.js                          # Main API server
‚îú‚îÄ‚îÄ cli.js                            # CLI tool for testing
‚îú‚îÄ‚îÄ server.js                         # Alternative server entry point
‚îú‚îÄ‚îÄ config/
‚îÇ   ‚îî‚îÄ‚îÄ index.js                      # Configuration management
‚îú‚îÄ‚îÄ services/
‚îÇ   ‚îú‚îÄ‚îÄ costControl.js                # Usage tracking & billing
‚îÇ   ‚îú‚îÄ‚îÄ queueService.js               # Unified Redis/DB queue system
‚îÇ   ‚îú‚îÄ‚îÄ shieldService.js              # Automated moderation
‚îÇ   ‚îú‚îÄ‚îÄ roastPromptTemplate.js        # Master prompt template system (v1)
‚îÇ   ‚îú‚îÄ‚îÄ roastGeneratorEnhanced.js     # Enhanced roast generation with RQC
‚îÇ   ‚îú‚îÄ‚îÄ csvRoastService.js            # CSV-based reference roast system
‚îÇ   ‚îú‚îÄ‚îÄ openai.js                     # OpenAI integration
‚îÇ   ‚îú‚îÄ‚îÄ perspective.js                # Perspective API
‚îÇ   ‚îî‚îÄ‚îÄ twitter.js                    # Legacy Twitter bot
‚îú‚îÄ‚îÄ workers/
‚îÇ   ‚îú‚îÄ‚îÄ BaseWorker.js                 # Base worker class
‚îÇ   ‚îú‚îÄ‚îÄ FetchCommentsWorker.js        # Comment fetching
‚îÇ   ‚îú‚îÄ‚îÄ AnalyzeToxicityWorker.js      # Toxicity analysis
‚îÇ   ‚îú‚îÄ‚îÄ GenerateReplyWorker.js        # Roast generation
‚îÇ   ‚îú‚îÄ‚îÄ ShieldActionWorker.js         # Moderation actions
‚îÇ   ‚îî‚îÄ‚îÄ cli/
‚îÇ       ‚îú‚îÄ‚îÄ start-workers.js          # Worker management
‚îÇ       ‚îú‚îÄ‚îÄ worker-status.js          # Status monitoring  
‚îÇ       ‚îî‚îÄ‚îÄ queue-manager.js          # Queue management
‚îú‚îÄ‚îÄ integrations/
‚îÇ   ‚îú‚îÄ‚îÄ twitter/twitterService.js     # Twitter API v2
‚îÇ   ‚îú‚îÄ‚îÄ youtube/youtubeService.js     # YouTube Data API
‚îÇ   ‚îú‚îÄ‚îÄ instagram/instagramService.js # Instagram Basic API
‚îÇ   ‚îú‚îÄ‚îÄ facebook/facebookService.js   # Facebook Graph API
‚îÇ   ‚îú‚îÄ‚îÄ discord/discordService.js     # Discord Bot API
‚îÇ   ‚îú‚îÄ‚îÄ twitch/twitchService.js       # Twitch API
‚îÇ   ‚îú‚îÄ‚îÄ reddit/redditService.js       # Reddit API
‚îÇ   ‚îú‚îÄ‚îÄ tiktok/tiktokService.js       # TikTok Business API
‚îÇ   ‚îî‚îÄ‚îÄ bluesky/blueskyService.js     # Bluesky AT Protocol
‚îî‚îÄ‚îÄ utils/
    ‚îî‚îÄ‚îÄ logger.js                     # Logging utility

database/
‚îî‚îÄ‚îÄ schema.sql                        # Multi-tenant PostgreSQL schema

tests/
‚îú‚îÄ‚îÄ unit/
‚îÇ   ‚îú‚îÄ‚îÄ services/                     # Service unit tests
‚îÇ   ‚îî‚îÄ‚îÄ workers/                      # Worker unit tests
‚îú‚îÄ‚îÄ integration/
‚îÇ   ‚îî‚îÄ‚îÄ multiTenantWorkflow.test.js   # E2E workflow tests
‚îî‚îÄ‚îÄ helpers/
    ‚îî‚îÄ‚îÄ testUtils.js                  # Test utilities
```

## Environment Variables

Set these environment variables for API integrations:

**Core Database & Queue:**
- `SUPABASE_URL` - Supabase project URL
- `SUPABASE_SERVICE_KEY` - Supabase service key (for server operations)
- `SUPABASE_ANON_KEY` - Supabase anonymous key (for client operations)
- `UPSTASH_REDIS_REST_URL` - Upstash Redis REST URL for serverless queues
- `UPSTASH_REDIS_REST_TOKEN` - Upstash Redis REST token
- `REDIS_URL` - Standard Redis URL (fallback)

**AI & Moderation APIs:**
- `OPENAI_API_KEY` - OpenAI API key for roast generation and content moderation
- `PERSPECTIVE_API_KEY` - Google Perspective API key for toxicity detection
- `NODE_ENV` - Set to 'production' to disable debug logging
- `DEBUG` - Set to 'true' to enable detailed logging

**Platform Integrations:**
- `TWITTER_BEARER_TOKEN` - Twitter Bearer Token for reading
- `TWITTER_APP_KEY` - Twitter Consumer Key
- `TWITTER_APP_SECRET` - Twitter Consumer Secret  
- `TWITTER_ACCESS_TOKEN` - Twitter Access Token for posting
- `TWITTER_ACCESS_SECRET` - Twitter Access Token Secret
- `YOUTUBE_API_KEY` - YouTube Data API v3 key
- `INSTAGRAM_ACCESS_TOKEN` - Instagram Basic Display API token
- `FACEBOOK_ACCESS_TOKEN` - Facebook Graph API token
- `DISCORD_BOT_TOKEN` - Discord bot token
- `TWITCH_CLIENT_ID` - Twitch API client ID
- `TWITCH_CLIENT_SECRET` - Twitch API client secret
- `REDDIT_CLIENT_ID` - Reddit API client ID
- `REDDIT_CLIENT_SECRET` - Reddit API client secret

**Optional Configuration:**
- `ROASTR_API_KEY` - Custom API key for /roast endpoint authentication
- `ROAST_API_URL` - URL of roast API (optional, defaults to production)
- `SHIELD_ENABLED` - Enable Shield automated moderation (default: true for Pro+ plans)

### Setting up OpenAI API for real roast generation:

1. Get an API key from [OpenAI Platform](https://platform.openai.com/api-keys)
2. Create a `.env` file in the project root:
   ```
   OPENAI_API_KEY=your_openai_api_key_here
   ```
3. Run the CLI with real AI: `npm run roast "tu comentario aqu√≠"`

If the OpenAI API fails, the CLI automatically falls back to the mock generator.

### Setting up Twitter Integration:

1. Create a Twitter Developer account at [developer.twitter.com](https://developer.twitter.com)
2. Create a new project and application
3. Configure app permissions to "Read and Write" 
4. Generate OAuth 1.0a tokens (for posting) and Bearer Token (for reading)
5. Add all credentials to `.env` file
6. Run `npm run twitter` to start the bot

## Multi-Tenant Architecture

The system is built on a comprehensive multi-tenant architecture designed for scale:

### Core Components

- **API Layer**: Express server with multi-tenant authentication and organization-scoped endpoints
- **Database Layer**: PostgreSQL with Row Level Security (RLS) for complete tenant isolation
- **Queue System**: Unified Redis/Upstash + Database queue management with priority support
- **Worker System**: Dedicated background workers for scalable comment processing
- **Cost Control**: Usage tracking, billing integration, and automatic limit enforcement
- **Shield System**: Automated content moderation with escalating actions

### Worker Architecture

1. **FetchCommentsWorker**: Fetches comments from 9 social media platforms
2. **AnalyzeToxicityWorker**: Analyzes content toxicity using Perspective API + OpenAI fallback
3. **GenerateReplyWorker**: Generates AI roast responses with cost control
4. **ShieldActionWorker**: Executes automated moderation actions (mute, block, report)

### Data Flow

```
Comment Detection ‚Üí Queue (fetch_comments)
    ‚Üì
Comment Fetching ‚Üí Store in Database ‚Üí Queue (analyze_toxicity)
    ‚Üì
Toxicity Analysis ‚Üí Update Database ‚Üí Queue (generate_reply) + Shield Analysis
    ‚Üì
Response Generation ‚Üí Store Roast ‚Üí Queue (post_response)
    ‚Üì
Shield Actions (if needed) ‚Üí Queue (shield_action) [Priority 1]
    ‚Üì
Platform Actions ‚Üí Moderation Complete
```

### Scaling Features

- **Horizontal scaling** via multiple worker instances
- **Priority-based job processing** (Shield actions get priority 1)
- **Automatic failover** from Redis to Database queues
- **Cost-based throttling** to prevent overages
- **Real-time monitoring** and alerting

## Master Prompt Template System (v1-roast-prompt)

The roast generation system has been enhanced with a comprehensive master prompt template that ensures consistency, quality, and personalization across all roast generations.

### Key Features

- **Dynamic Field Replacement**: Supports placeholders for original comment, category, references, and user tone
- **Comment Categorization**: Automatically categorizes comments (insults, body shaming, political, etc.)
- **Reference Integration**: Includes similar roasts from CSV database as examples
- **User Tone Mapping**: Personalizes responses based on user preferences and plan features
- **Version Control**: Template versioning for future improvements and A/B testing
- **üîí Security Protection**: Robust input sanitization and prompt injection prevention

### Security Features (Issue #127)

- **Prompt Injection Protection**: Automatically sanitizes malicious template placeholders (`{{placeholder}}` patterns)
- **Input Validation**: Strict validation for `originalComment` (type, length, content)
- **Error Traceability**: Comprehensive logging with error context and version tracking
- **Length Limits**: 2000 character limit to prevent DoS attacks
- **Fallback System**: Graceful degradation when validation fails or errors occur

### GDPR Rate Limiting (Issue #115)

The system implements strict rate limiting for GDPR-sensitive endpoints to prevent DoS and brute force attacks:

- **Account Deletion**: 3 attempts per hour per IP/user (`DELETE /api/user/account`)
- **Data Export**: 5 attempts per hour per IP/user (`GET /api/user/data-export`)  
- **Data Download**: 10 attempts per hour per IP/token (`GET /api/user/data-export/download/:token`)
- **Deletion Cancellation**: 5 attempts per hour per IP/user (`POST /api/user/account/deletion/cancel`)
- **Global GDPR Limit**: 20 total GDPR requests per hour per IP across all endpoints

Rate limiters are automatically disabled in test environment and can be configured via feature flags.

### Template Structure

```
Tu tarea es generar una respuesta sarc√°stica e ingeniosa...

üí¨ COMENTARIO ORIGINAL: {{original_comment}}
üé≠ CATEGOR√çA DEL COMENTARIO: {{comment_category}}
üìö EJEMPLOS DE ROASTS: {{reference_roasts_from_CSV}}
üë§ TONO PERSONAL: {{user_tone}}
```

### Integration Points

- **RoastGeneratorEnhanced**: Used in both basic moderation and advanced RQC modes
- **GenerateReplyWorker**: Integrated into the worker pipeline for queue processing
- **Platform Constraints**: Automatically adds platform-specific character limits and style guides
- **Plan Differentiation**: Free plans exclude references, Pro+ plans include full examples
- **Security Layer**: All inputs sanitized before template processing

### Usage Example

```javascript
const promptTemplate = new RoastPromptTemplate();
const prompt = await promptTemplate.buildPrompt({
  originalComment: "Esta aplicaci√≥n es horrible",
  toxicityData: { score: 0.5, categories: ['TOXICITY'] },
  userConfig: { tone: 'sarcastic', humor_type: 'witty', intensity_level: 3 },
  includeReferences: true
});
```

## Twitter Bot Features

- **Mention Monitoring**: Automatically detects mentions to your Twitter account
- **Toxicity Filtering**: Uses stub (always true) with skeleton for Perspective API
- **Roast Generation**: Calls your deployed API to generate responses
- **Duplicate Prevention**: Tracks processed tweets in `data/processed_tweets.json`
- **Rate Limiting**: Adds delays between responses to respect API limits
- **Error Handling**: Graceful failure handling and detailed logging

## Orquestaci√≥n y Reglas

### Funci√≥n de Orquestador

- **Actuar como orquestador del resto de subagentes**: Coordinar y supervisar las tareas de todos los agentes especializados del sistema.
- **Mantener un archivo de contexto global spec.md actualizado**: Gestionar un documento central que refleje el estado actual de la especificaci√≥n del sistema.
- **Cuando un subagente cree un *.md t√°ctico** (ej: shield.md, ui.md...): debe a√±adir un bloque en spec.md dentro de la secci√≥n correspondiente para mantener la coherencia documental.
- **Invocar siempre al Test Engineer Agent** tras cambios en src/ o en documentos de dise√±o (ux.md, ui.md, ui-whimsy.md) para generar tests + evidencias visuales con Playwright.

### Configuraci√≥n MCP Playwright

- **Para cualquier cambio de frontend**, el orquestador debe:
  - Ejecutar Playwright MCP para validaci√≥n visual automatizada
  - Capturar screenshots de las p√°ginas afectadas en m√∫ltiples viewports
  - Revisar consola del navegador y logs de red para detectar errores
  - Guardar un reporte completo en `docs/ui-review.md` con evidencias visuales
  - Verificar que la implementaci√≥n coincide con las especificaciones de dise√±o
- **Comando de verificaci√≥n MCP**: `/mcp list` para confirmar que Playwright est√° operativo
- **Ejecuci√≥n de validaci√≥n**: `/mcp exec playwright` para realizar capturas y an√°lisis visual

### Reglas de PR

- **Cada feature/tarea nueva = nueva PR**: No mezclar funcionalidades diferentes en una misma Pull Request.
- **No mezclar en PRs ya abiertas salvo fix de review**: Mantener el scope limitado de cada PR una vez abierta.
- **Si detectas commits fuera de scope ‚Üí detener y abrir nueva PR**: Evitar la deriva del alcance durante el desarrollo.
- **Documentar estas reglas tambi√©n en la plantilla de PR**: Asegurar que todos los colaboradores conozcan las normas.

### ‚≠ê Quality Standards (CR√çTICO)

**Ver docs/QUALITY-STANDARDS.md para detalles completos.**

**Requisitos NO NEGOCIABLES para mergear PR:**
1. ‚úÖ Sin conflictos con main
2. ‚úÖ CI/CD passing (todos los jobs verdes)
3. ‚úÖ **0 comentarios de CodeRabbit** (CERO, no "casi cero")

**Pre-Flight Checklist OBLIGATORIO antes de `gh pr create`:**
- Tests completos y pasando
- Documentaci√≥n actualizada (CLAUDE.md, spec.md, nodos GDD)
- Code quality (sin console.logs, TODOs, c√≥digo muerto)
- Self-review exhaustivo (como si fueras CodeRabbit)

**Si CodeRabbit comenta:**
- NO pedir merge
- Implementar TODAS las sugerencias
- Push de correcciones
- Esperar nueva review
- Repetir hasta 0 comentarios

**Mentalidad:** Producto monetizable, no proyecto de instituto. Calidad > Velocidad.

### Reglas de Commits y Tests

- **Commit sin tests no permitido**: Todo c√≥digo nuevo debe incluir pruebas correspondientes.
- **Si se detecta c√≥digo nuevo sin tests asociados ‚Üí coordinar con Test Engineer** para generar los tests antes de cerrar la tarea.
- **Cambios en UI/frontend deben incluir evidencias visuales**: capturas + report.md en docs/test-evidence/ para validar la implementaci√≥n visual.

### Task Assessment (FASE 0 - OBLIGATORIA)

**IMPORTANTE**: Antes de cualquier planning o implementaci√≥n, SIEMPRE eval√∫a el estado actual de la tarea.

#### Criterio de Decisi√≥n: ¬øAssessment Simple o Completo?

- **Assessment Simple** (Orquestador inline):
  - Tareas con ‚â§ 2 criterios de aceptaci√≥n
  - Issues de tipo: docs, config simple, fix peque√±o
  - Ejecuci√≥n: Orquestador hace b√∫squeda inline y ejecuta tests si existen

- **Assessment Completo** (Task Assessor Agent):
  - Tareas con ‚â• 3 criterios de aceptaci√≥n
  - Issues P0/P1 cr√≠ticas
  - Features complejas, integraciones, refactors
  - Ejecuci√≥n: Invocar Task Assessor Agent

#### Workflow de Assessment

1. **Identificar Tipo de Assessment**:
   - Leer issue/tarea completa
   - Contar criterios de aceptaci√≥n
   - Determinar complejidad

2. **Assessment Simple** (Orquestador):
   ```bash
   # Buscar archivos relacionados
   find tests/ src/ docs/ -name "*<keyword>*"

   # Si hay tests, ejecutarlos
   npm test -- <keyword>

   # Determinar recomendaci√≥n inline:
   # - Si tests pasan + AC cumplidos ‚Üí CLOSE
   # - Si tests fallan ‚Üí FIX
   # - Si implementaci√≥n parcial ‚Üí ENHANCE
   # - Si no existe nada ‚Üí CREATE
   ```

   Documentar decisi√≥n en el plan directamente.

3. **Assessment Completo** (Task Assessor Agent):
   ```
   Invocar: Task Assessor Agent con issue number
   Output: docs/assessment/<issue>.md
   Resultado: Recomendaci√≥n CREATE | FIX | ENHANCE | CLOSE
   ```

4. **Actuar seg√∫n Recomendaci√≥n**:
   - **CLOSE**: Cerrar issue con evidencia, no proceder a planning
   - **FIX**: Planning enfocado en arreglar lo que falla
   - **ENHANCE**: Planning para mejorar lo existente
   - **CREATE**: Planning para implementar desde cero

#### Ejemplos de Assessment

**Ejemplo 1 - Assessment Simple (Orquestador inline):**
```
Issue #450: "Actualizar README con nuevos comandos"
- AC: 1 (a√±adir comandos al README)
- Tipo: docs
‚Üí Orquestador inline: find README.md, revisar contenido
‚Üí Recomendaci√≥n: ENHANCE (README existe, a√±adir secci√≥n)
‚Üí Procede a planning simple
```

**Ejemplo 2 - Assessment Completo (Task Assessor Agent):**
```
Issue #408: "Shield integration tests"
- AC: 5 (acciones, registro, no respuestas, escalamiento, logs)
- Tipo: test integration P0
‚Üí Invocar Task Assessor Agent
‚Üí Agent encuentra: tests/integration/shield-issue-408.test.js
‚Üí Agent ejecuta: 11 tests failing
‚Üí Recomendaci√≥n: FIX (tests existen pero fallan)
‚Üí Procede a planning para FIX
```

### Planning Mode

- **Antes de implementar cualquier feature/tarea, genera siempre un plan en modo texto (planning mode)**.
- **El plan debe incluir secci√≥n "Estado Actual"** basada en el assessment realizado.
- **El plan debe describir**: pasos de dise√±o, subagentes a usar, archivos afectados, criterios de validaci√≥n.
- **Guarda el plan en `docs/plan/<issue>.md`**.
- **‚ö†Ô∏è CR√çTICO: Despu√©s de guardar el plan, CONTIN√öA AUTOM√ÅTICAMENTE con la implementaci√≥n**.
  - **NO esperes confirmaci√≥n** del usuario
  - **NO preguntes** "¬øprocedemos?" o "¬øcontinuamos?"
  - El plan es para **documentar**, no para **pedir permiso**
  - **EJECUTA el plan inmediatamente** despu√©s de guardarlo
  - Solo te detienes si encuentras un **bloqueador t√©cnico real** (API down, credenciales faltantes, etc.)

### Gesti√≥n de Agentes Relevantes (GDD Phase 4)

- **Cada nodo en `docs/nodes/*.md` debe mantener actualizada la secci√≥n "## Agentes Relevantes"**.
- **Reglas de sincronizaci√≥n**:
  - Si durante una tarea invocas a un agente que **no est√° listado** en "Agentes Relevantes" del nodo ‚Üí **a√±√°delo autom√°ticamente**.
  - Si detectas que un agente listado **ya no aplica** al nodo ‚Üí **elim√≠nalo**.
  - Mant√©n la lista ordenada alfab√©ticamente para facilitar la lectura.
- **Validaci√≥n autom√°tica**: Ejecuta `node scripts/resolve-graph.js --validate` antes de cerrar cualquier PR para verificar que todos los nodos tienen secci√≥n de agentes v√°lida.
- **Checklist obligatorio al cerrar nodo/PR**:
  - [ ] Le√≠ `spec.md` y el archivo `.md` del nodo afectado.
  - [ ] Revis√© que `## Agentes Relevantes` refleja los agentes efectivamente usados en esta tarea.
  - [ ] A√±ad√≠ agentes que invocamos y no estaban listados.
  - [ ] Elimin√© agentes que ya no son relevantes para este nodo.
  - [ ] Ejecut√© `node scripts/resolve-graph.js --validate` y no hay errores.
  - [ ] Confirm√© que `spec.md` tiene la tabla global de nodos-agentes sincronizada.
  - [ ] Gener√© reporte de validaci√≥n con `node scripts/resolve-graph.js --report`.

**Tabla global de nodos-agentes**: Ver secci√≥n "Node-Agent Matrix" en `spec.md` para referencia r√°pida.

### GDD Activation - Issue Analysis & Context Loading (October 3, 2025)

**IMPORTANTE:** A partir de ahora, el Orchestrator debe usar Graph Driven Development (GDD) para **todas las issues**, cargando solo los nodos relevantes en lugar de spec.md completo.

#### 1. Issue Analysis (Autom√°tico)

**Cuando el usuario menciona un n√∫mero de issue** (ej: "Trabajemos en Issue #408"):

1. **Fetch issue metadata:**
   ```bash
   gh issue view 408 --json labels,title,body
   ```

2. **Map labels ‚Üí nodes** usando esta tabla:

   | Label | Nodos Afectados | Comando |
   |-------|----------------|---------|
   | `area:shield` | shield, multi-tenant | `node scripts/resolve-graph.js shield` |
   | `area:billing` | cost-control, plan-features, multi-tenant | `node scripts/resolve-graph.js cost-control` |
   | `area:platforms` | social-platforms, platform-constraints | `node scripts/resolve-graph.js social-platforms` |
   | `area:workers` | queue-system, multi-tenant | `node scripts/resolve-graph.js queue-system` |
   | `area:ui` | roast, persona, tone | `node scripts/resolve-graph.js roast` |
   | `area:demo` | roast, shield, queue-system | `node scripts/resolve-graph.js roast` |
   | `area:multitenant` | multi-tenant | `node scripts/resolve-graph.js multi-tenant` |
   | `area:publisher` | queue-system, social-platforms | `node scripts/resolve-graph.js queue-system` |
   | `area:observability` | ALL nodes | `cat docs/nodes/*.md` |
   | `area:reliability` | queue-system, shield, multi-tenant | `node scripts/resolve-graph.js queue-system` |
   | `test:e2e` | ALL nodes (pipeline completo) | `cat docs/nodes/*.md` |
   | `test:integration` | depende de otros labels | Ver arriba |
   | `test:unit` | nodo espec√≠fico del t√≠tulo | Parsear keywords |

3. **Keyword fallback** (si no hay label `area:*`), buscar en t√≠tulo/body:

   | Keywords | Nodo Principal |
   |----------|----------------|
   | "shield", "moderaci√≥n", "ofensor" | shield |
   | "billing", "stripe", "plan", "entitlements" | cost-control |
   | "worker", "queue", "redis", "job" | queue-system |
   | "roast", "generaci√≥n", "prompt", "variante" | roast |
   | "multi-tenant", "RLS", "organization" | multi-tenant |
   | "platform", "twitter", "discord", "integration" | social-platforms |
   | "persona", "tone", "style", "humor" | persona |
   | "demo mode", "fixtures", "seeds" | roast |
   | "publisher", "publicaci√≥n", "post" | queue-system |

4. **Resolve dependencies:**
   ```bash
   node scripts/resolve-graph.js <nodes>
   ```

5. **Load ONLY resolved nodes** (NO spec.md)

6. **Announce context loaded:**
   ```
   üîç Analyzing Issue #408...

   üìä GDD Node Mapping:
   - Primary node: shield
   - Dependencies: multi-tenant, plan-features, cost-control

   üìñ Loading context (2,050 lines):
     ‚úì docs/nodes/shield.md (680 lines)
     ‚úì docs/nodes/multi-tenant.md (707 lines)
     ‚úì docs/nodes/plan-features.md (194 lines)
     ‚úì docs/nodes/cost-control.md (470 lines)

   üíæ Context reduction: 71% (7,034 ‚Üí 2,050 lines)
   ‚ö° Token savings: ~14,500 tokens

   üöÄ Ready to work on Shield integration tests!
   ```

#### 2. During Development

**ALWAYS:**
- ‚úÖ Read nodes, NOT spec.md (unless `test:e2e` or `area:observability`)
- ‚úÖ Update affected nodes when code changes
- ‚úÖ Add agents to "Agentes Relevantes" if invoked but not listed
- ‚úÖ Run `node scripts/resolve-graph.js --validate` before commits
- ‚úÖ Keep node docs synchronized with code

**NEVER:**
- ‚ùå Load entire spec.md (unless explicitly required)
- ‚ùå Skip node updates after code changes
- ‚ùå Forget to add new agents to "Agentes Relevantes"
- ‚ùå Commit without validation passing

#### 3. Before Closing PR

**Mandatory GDD Checklist (in addition to existing checklist):**
- [ ] Verified "Agentes Relevantes" reflects agents actually used
- [ ] Added missing agents, removed irrelevant agents
- [ ] Ran `node scripts/resolve-graph.js --validate` ‚Üí no errors
- [ ] Generated report: `node scripts/resolve-graph.js --report`
- [ ] Included GDD summary in PR description:
  ```markdown
  ## üìä GDD Summary

  **Nodes Updated:**
  - shield.md (added hide/block/report methods)
  - multi-tenant.md (RLS policies updated)

  **Context Used:** 2,050 lines (71% reduction vs spec.md)
  **Validation:** ‚úÖ All checks passing
  **Agent Sync:** ‚úÖ Up to date
  ```

#### 4. Fallback Strategy

**Si no puedes determinar nodos autom√°ticamente:**
1. Preguntar al usuario: "I see Issue #XXX. Which feature area? (shield, billing, workers, etc.)"
2. Usuario responde ‚Üí mapear a nodos
3. Si a√∫n no est√° claro ‚Üí cargar nodos comunes: `roast, shield, queue-system` (~2,000 l√≠neas)
4. Explicar contexto cargado y pedir confirmaci√≥n

**NUNCA cargar spec.md por defecto.**

#### 5. Examples

**Example 1: Shield Integration (Issue #408)**
```
USER: "Trabajemos en Issue #408"

ORCHESTRATOR:
1. gh issue view 408 --json labels,title,body
2. Labels: area:shield, test:integration, priority:P0
3. Map: area:shield ‚Üí shield
4. node scripts/resolve-graph.js shield
5. Load: shield.md, multi-tenant.md, plan-features.md, cost-control.md
6. Announce: "Loading 2,050 lines (71% reduction)"
7. Work on issue using only those 4 nodes
8. Update shield.md when adding new code
9. Validate before commit
10. Include GDD summary in PR
```

**Example 2: Multi-tenant RLS (Issue #412)**
```
USER: "Issue #412 - multi-tenant RLS tests"

ORCHESTRATOR:
1. Labels: area:multitenant, test:integration, priority:P0
2. Map: area:multitenant ‚Üí multi-tenant
3. node scripts/resolve-graph.js multi-tenant
4. Load: multi-tenant.md (leaf node, no deps = 707 lines)
5. Announce: "Loading 707 lines (90% reduction)"
6. Work on RLS tests using only multi-tenant.md
7. Update multi-tenant.md with new RLS policies
8. Validate and commit
```

**Full details:** See `docs/GDD-ACTIVATION-GUIDE.md` for complete mapping tables and workflows.

## Runtime Validation Workflow (GDD 2.0)

> **For full details, see:** `docs/GDD-ACTIVATION-GUIDE.md#runtime-validation`

The GDD Runtime Validator continuously monitors and validates the coherence between `system-map.yaml`, `docs/nodes/**`, `spec.md`, and source code (`src/**`).

**Key Commands:**
```bash
node scripts/validate-gdd-runtime.js --full    # Validate entire system
node scripts/validate-gdd-runtime.js --ci      # CI mode (exit 1 on errors)
node scripts/watch-gdd.js                      # Watch mode (development)
```

**Validation Rules:** Graph structure, documentation sync, link integrity, code integration

**Status Levels:** üü¢ HEALTHY | üü° WARNING | üî¥ CRITICAL

**Before PR Merge:** Run full validation, ensure üü¢ HEALTHY or acceptable üü° WARNING

---

## Node Health Scoring System (GDD 2.0 - Phase 7)

> **For full details, see:** `docs/GDD-ACTIVATION-GUIDE.md#health-scoring`

Provides quantitative metrics (0-100) for each GDD node based on 5 weighted factors: Sync Accuracy (30%), Update Freshness (20%), Dependency Integrity (20%), Coverage Evidence (20%), Agent Relevance (10%).

**Commands:**
```bash
node scripts/score-gdd-health.js              # Standalone scoring
node scripts/validate-gdd-runtime.js --score  # Combined validation + scoring
```

**Status Levels:** üü¢ HEALTHY (80-100) | üü° DEGRADED (50-79) | üî¥ CRITICAL (<50)

**Before PR Merge:** Average score > 75, no critical nodes

## Predictive Drift Detection (GDD 2.0 - Phase 8)

> **For full details, see:** `docs/GDD-ACTIVATION-GUIDE.md#drift-prediction`

Analyzes historical patterns to calculate a **Drift Risk Score (0-100)** for each node based on: last updated, active warnings, test coverage, health score, and recent activity.

**Commands:**
```bash
node scripts/predict-gdd-drift.js --full         # Run drift prediction
node scripts/predict-gdd-drift.js --ci           # CI mode (exit 1 if high-risk)
node scripts/predict-gdd-drift.js --create-issues # Create issues for high-risk nodes
```

**Risk Levels:** üü¢ Healthy (0-30) | üü° At Risk (31-60) | üî¥ Likely Drift (61-100)

**Before PR:** Check drift risk, address nodes with risk > 60

---

## CI/CD GDD Automation (Phase 12)

> **For full details, see:** `docs/GDD-ACTIVATION-GUIDE.md#cicd-automation`

The GDD system is fully integrated into the CI/CD pipeline with automated validation, repair, and issue management.

**Configuration:** `.gddrc.json` (min_health_score: 95, auto_fix: true, block_merge_below_health: 95)

**Workflows:**
1. **GDD Validation** (`.github/workflows/gdd-validate.yml`) - Runs on PR to main/develop, validates nodes, scores health, predicts drift, posts PR comment, blocks merge if health < 95
2. **GDD Auto-Repair** (`.github/workflows/gdd-repair.yml`) - Auto-fixes missing agent sections, broken links, missing node references

**Before PR:**
```bash
node scripts/validate-gdd-runtime.js --full
node scripts/predict-gdd-drift.js --full
node scripts/compute-gdd-health.js --threshold=95
node scripts/auto-repair-gdd.js --auto-fix  # If needed
```

**Success Criteria:** Health ‚â• 95, no critical nodes, drift < 60

**Auto-created Issues:** Validation failed, auto-repair failed, high drift risk, manual review required

---

### Tareas al Cerrar

**üö® VERIFICACI√ìN OBLIGATORIA antes de marcar tarea como completa:**

1. **Tests DEBEN PASAR al 100%**:
   ```bash
   npm test -- <relevant-tests>
   # O espec√≠fico:
   npm test <test-file>.test.js
   ```
   - ‚úÖ **0 tests fallando** - Si hay 1 solo test rojo, la tarea NO est√° completa
   - ‚ùå **NUNCA marcar completa con tests failing**
   - Si tests fallan ‚Üí arreglar ANTES de continuar

2. **Pre-Flight Checklist ejecutado**:
   - [ ] Tests pasando (ver punto 1)
   - [ ] Documentaci√≥n actualizada
   - [ ] Code quality verificado
   - [ ] Self-review completado

3. **Documentaci√≥n actualizada**:
   - **spec.md** reflejando nuevos cambios
   - **Nodos GDD** con status actualizado
   - **Mapa de cobertura de tests** + evidencias visuales
   - **Changelog detallado** en la PR

**‚ö†Ô∏è Si encuentras tests failing:**
- NO contin√∫es con siguiente tarea
- NO marques como completa
- Arregla los tests AHORA
- Re-ejecuta para verificar
- Solo entonces procede